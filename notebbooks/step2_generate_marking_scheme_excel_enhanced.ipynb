{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d61b374",
   "metadata": {},
   "source": [
    "# Step 2: Extract Marking Scheme to Excel (Enhanced)\n",
    "\n",
    "Use Gemini to parse the Word marking scheme into structured Excel sheets with enhanced error handling, validation, and progress tracking.\n",
    "\n",
    "**Enhanced Features:**\n",
    "- ‚úÖ Comprehensive error handling and validation\n",
    "- ‚úÖ Enhanced progress tracking and logging\n",
    "- ‚úÖ Improved markdown formatting and structure\n",
    "- ‚úÖ Robust file handling and backup\n",
    "- ‚úÖ Detailed validation and quality checks\n",
    "- ‚úÖ Professional output formatting\n",
    "\n",
    "Configure the exam `prefix` and dataset folder in the next cell before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f987fbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:01,753 - INFO - ‚úì Input file validated: ../sample/VTC Test Marking Scheme.docx\n",
      "2026-01-04 23:31:01,754 - INFO - ‚úì Output file will be: ../sample/VTC Test Marking Scheme.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced Step 2: Extract Marking Scheme to Excel initialized\n",
      "‚úì Session started at: 2026-01-04 23:31:01\n",
      "üìÅ Input: ../sample/VTC Test Marking Scheme.docx\n",
      "üìÅ Output: ../sample/VTC Test Marking Scheme.xlsx\n"
     ]
    }
   ],
   "source": [
    "from grading_utils import setup_paths, init_gemini_client\n",
    "from google.genai import types\n",
    "import mammoth\n",
    "import html2text\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Enhanced logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Enhanced Step 2: Extract Marking Scheme to Excel initialized\")\n",
    "print(f\"‚úì Session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Configuration\n",
    "prefix = \"VTC Test\"  # Change this to your exam name\n",
    "dataset = \"sample\"   # Change to your dataset folder\n",
    "\n",
    "# Setup paths with validation\n",
    "try:\n",
    "    paths = setup_paths(prefix, dataset)\n",
    "    marking_scheme_word_file = f\"../{dataset}/{prefix} Marking Scheme.docx\"\n",
    "    marking_scheme_excel_file = paths[\"marking_scheme_file\"]\n",
    "    \n",
    "    # Validate input file exists\n",
    "    if not os.path.exists(marking_scheme_word_file):\n",
    "        raise FileNotFoundError(f\"Marking scheme file not found: {marking_scheme_word_file}\")\n",
    "    \n",
    "    logger.info(f\"‚úì Input file validated: {marking_scheme_word_file}\")\n",
    "    logger.info(f\"‚úì Output file will be: {marking_scheme_excel_file}\")\n",
    "    \n",
    "    print(f\"üìÅ Input: {marking_scheme_word_file}\")\n",
    "    print(f\"üìÅ Output: {marking_scheme_excel_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Setup failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64616fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:01,797 - INFO - ‚úì Gemini client initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Vertex AI Express Mode initialized\n",
      "ü§ñ Gemini AI client ready\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Gemini client initialization with error handling\n",
    "try:\n",
    "    client = init_gemini_client()\n",
    "    logger.info(\"‚úì Gemini client initialized successfully\")\n",
    "    print(\"ü§ñ Gemini AI client ready\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Failed to initialize Gemini client: {e}\")\n",
    "    print(f\"‚ùå Gemini initialization failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d68d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:01,804 - INFO - Processing Word document: ../sample/VTC Test Marking Scheme.docx\n",
      "2026-01-04 23:31:01,806 - INFO - File size: 18,126 bytes\n",
      "2026-01-04 23:31:01,830 - INFO - ‚úì Extracted 4,271 characters of markdown content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document processed successfully\n",
      "üìÑ Content length: 4,271 characters\n",
      "\n",
      "üìã Document Preview:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Detailed Marking Scheme (0-10 Scale)**\n",
       "\n",
       "Use the following rubric to determine the score for each q.\n",
       "\n",
       "**Q1: The Role of VTC**  \n",
       "The VTC is the largest provider of **VPET** in Hong Kong. Briefly explain what **VPET** stands for and why it is important for Hong Kong‚Äôs workforce development.\n",
       "\n",
       "  * **Answer:** VPET stands for **Vocational and Professional Education and Training**. It is important because it provides students with practical skills and specialized knowledge needed by industries, ensuring Hong Kong has a skilled labor force to support the economy.\n",
       "  * **Marking Breakdown:**\n",
       "    * **[2 marks]** Correctly stating \"Vocational and Professional Education and Training\".\n",
       "    * **[4 marks]** Explaining that it focuses on _practical skills_ or _specialized trades_.\n",
       "    * **[4 marks]** Explaining the benefit to the workforce (reducing skills gap, employment readiness).\n",
       "\n",
       "\n",
       "\n",
       "**Q2: Member Institutions**  \n",
       "Compare **IVE (Hong Kong Institute of Vocational Education)** and **THEi (Technologic..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enhanced document processing with comprehensive error handling\n",
    "def process_word_document(file_path):\n",
    "    \"\"\"Process Word document with enhanced error handling and validation\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Processing Word document: {file_path}\")\n",
    "        \n",
    "        # Validate file exists and is readable\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(file_path)\n",
    "        logger.info(f\"File size: {file_size:,} bytes\")\n",
    "        \n",
    "        # Convert .docx to HTML using mammoth\n",
    "        with open(file_path, \"rb\") as docx_file:\n",
    "            result = mammoth.convert_to_html(docx_file)\n",
    "            html_content = result.value\n",
    "            \n",
    "            # Check for conversion warnings\n",
    "            if result.messages:\n",
    "                logger.warning(f\"Mammoth conversion warnings: {len(result.messages)}\")\n",
    "                for msg in result.messages[:5]:  # Show first 5 warnings\n",
    "                    logger.warning(f\"  - {msg}\")\n",
    "        \n",
    "        # Convert HTML to markdown using html2text\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.body_width = 0  # Don't wrap text\n",
    "        h.ignore_images = True\n",
    "        h.ignore_tables = False\n",
    "        \n",
    "        markdown_content = h.handle(html_content)\n",
    "        \n",
    "        # Validate content\n",
    "        if not markdown_content.strip():\n",
    "            raise ValueError(\"No content extracted from document\")\n",
    "        \n",
    "        content_length = len(markdown_content)\n",
    "        logger.info(f\"‚úì Extracted {content_length:,} characters of markdown content\")\n",
    "        \n",
    "        return markdown_content, html_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Document processing failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Process the document\n",
    "try:\n",
    "    markdown_content, html_content = process_word_document(marking_scheme_word_file)\n",
    "    print(\"‚úÖ Document processed successfully\")\n",
    "    print(f\"üìÑ Content length: {len(markdown_content):,} characters\")\n",
    "    \n",
    "    # Display preview of markdown content\n",
    "    print(\"\\nüìã Document Preview:\")\n",
    "    display(Markdown(markdown_content[:1000] + \"...\" if len(markdown_content) > 1000 else markdown_content))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Document processing failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2d26ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:01,841 - INFO - ‚úì Enhanced data models defined with validation\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Pydantic models with comprehensive validation\n",
    "class Question(BaseModel):\n",
    "    \"\"\"Enhanced question model with comprehensive validation\"\"\"\n",
    "    question_number: str = Field(\n",
    "        description=\"The question number (e.g., '1', '2', '22a', '22b', 'Q1','Q2')\"\n",
    "    )\n",
    "    question_text: str = Field(\n",
    "        description=\"The full question text\"\n",
    "    )\n",
    "    marking_scheme: str = Field(\n",
    "        description=\"Well-formatted marking scheme using markdown. Use bullet points (-), numbered lists (1., 2.), bold (**text**) for key terms, and clear line breaks. Include point allocations in parentheses (e.g., '- Key concept explained (2 marks)'). Structure should be clear and scannable.\"\n",
    "    )\n",
    "    marks: int = Field(\n",
    "        description=\"Total marks available for this question\"\n",
    "    )\n",
    "\n",
    "class MarkingSchemeResponse(BaseModel):\n",
    "    \"\"\"Enhanced wrapper class with validation\"\"\"\n",
    "    general_grading_guide: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"General grading guide for partial marks applicable to all questions, formatted in markdown\"\n",
    "    )\n",
    "    questions: List[Question] = Field(\n",
    "        description=\"List of questions with marking schemes and marks\"\n",
    "    )\n",
    "\n",
    "logger.info(\"‚úì Enhanced data models defined with validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17f884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:01,849 - INFO - AI extraction attempt 1/3\n",
      "2026-01-04 23:31:01,850 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Processing document with Gemini AI...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 23:31:48,023 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 23:31:48,033 - WARNING - Structured output not available, attempting text parsing\n",
      "2026-01-04 23:31:48,034 - ERROR - JSON parsing failed: Unterminated string starting at: line 1 column 1271 (char 1270)\n",
      "2026-01-04 23:31:48,034 - INFO - Retrying with adjusted parameters...\n",
      "2026-01-04 23:31:48,035 - INFO - AI extraction attempt 2/3\n",
      "2026-01-04 23:31:48,035 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 105\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mü§ñ Processing document with Gemini AI...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     questions_data, general_guide = \u001b[43mextract_marking_scheme_with_ai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarkdown_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ AI extraction successful!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Extracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(questions_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m questions\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mextract_marking_scheme_with_ai\u001b[39m\u001b[34m(markdown_content, max_retries)\u001b[39m\n\u001b[32m     43\u001b[39m config = types.GenerateContentConfig(\n\u001b[32m     44\u001b[39m     temperature=\u001b[32m0.1\u001b[39m,  \u001b[38;5;66;03m# Lower temperature for more consistent extraction\u001b[39;00m\n\u001b[32m     45\u001b[39m     top_p=\u001b[32m0.5\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     48\u001b[39m     response_schema=MarkingSchemeResponse,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# Send to Gemini using structured output\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-3-flash-preview\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparts\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Enhanced response processing\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m'\u001b[39m\u001b[33mparsed\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/google/genai/models.py:5203\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5201\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc > \u001b[32m0\u001b[39m:\n\u001b[32m   5202\u001b[39m   i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5203\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5204\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5205\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5207\u001b[39m   function_map = _extra_utils.get_function_map(parsed_config)\n\u001b[32m   5208\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/google/genai/models.py:3985\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3982\u001b[39m request_dict = _common.convert_to_dict(request_dict)\n\u001b[32m   3983\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3985\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3986\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   3990\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3991\u001b[39m ):\n\u001b[32m   3992\u001b[39m   return_value = types.GenerateContentResponse(sdk_http_response=response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1388\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1378\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\n\u001b[32m   1379\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1380\u001b[39m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1383\u001b[39m     http_options: Optional[HttpOptionsOrDict] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1384\u001b[39m ) -> SdkHttpResponse:\n\u001b[32m   1385\u001b[39m   http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1386\u001b[39m       http_method, path, request_dict, http_options\n\u001b[32m   1387\u001b[39m   )\n\u001b[32m-> \u001b[39m\u001b[32m1388\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1389\u001b[39m   response_body = (\n\u001b[32m   1390\u001b[39m       response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1391\u001b[39m   )\n\u001b[32m   1392\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers=response.headers, body=response_body)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1224\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1221\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m   1222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1224\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/tenacity/__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/tenacity/__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/tenacity/__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_post_retry_check_actions\u001b[39m(\u001b[38;5;28mself\u001b[39m, retry_state: \u001b[33m\"\u001b[39m\u001b[33mRetryCallState\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    399\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m         \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.after \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/tenacity/__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/google/genai/_api_client.py:1194\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1190\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1191\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1192\u001b[39m   )\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1194\u001b[39m   response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_httpx_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m      \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m   errors.APIError.raise_for_response(response)\n\u001b[32m   1202\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1203\u001b[39m       response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1204\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/data-disk/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1233\u001b[39m, in \u001b[36mSSLSocket.recv\u001b[39m\u001b[34m(self, buflen, flags)\u001b[39m\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1230\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1231\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1232\u001b[39m             \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1235\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv(buflen, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/ssl.py:1106\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[32m   1108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m x.args[\u001b[32m0\u001b[39m] == SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.suppress_ragged_eofs:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Enhanced AI processing with comprehensive error handling and retry logic\n",
    "def extract_marking_scheme_with_ai(markdown_content, max_retries=3):\n",
    "    \"\"\"Extract marking scheme using AI with enhanced error handling\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            logger.info(f\"AI extraction attempt {attempt + 1}/{max_retries}\")\n",
    "            \n",
    "            # Create enhanced prompt\n",
    "            prompt = f\"\"\"Please analyze this marking scheme document and extract structured, well-formatted data.\n",
    "\n",
    "**FORMATTING REQUIREMENTS for marking_scheme:**\n",
    "- Use markdown formatting (bullet points -, numbered lists 1., 2., bold **text**)\n",
    "- Each marking criterion should be on its own line\n",
    "- Show point allocations clearly (e.g., \"- Correct formula (2 marks)\")\n",
    "- Use clear hierarchy with proper indentation for sub-points\n",
    "- Add line breaks between major sections\n",
    "- Bold important terms or key concepts\n",
    "- Make it scannable and easy to read\n",
    "\n",
    "**EXTRACT:**\n",
    "\n",
    "1. **GENERAL GRADING GUIDE**: Extract any general grading guide or guidance for partial marks that applies to all/multiple questions (use markdown formatting)\n",
    "\n",
    "2. **FOR EACH QUESTION**: Extract:\n",
    "   - Question number (normalize to consistent format)\n",
    "   - Question text (complete question statement)\n",
    "   - **Marking scheme** (well-formatted with markdown, bullets, numbering, clear point allocation)\n",
    "   - Total marks available (must be a positive integer)\n",
    "\n",
    "**Important Guidelines:**\n",
    "- When extracting the marking_scheme for each question, incorporate any general grading principles that apply to that question's scoring\n",
    "- Ensure all questions have non-empty marking schemes\n",
    "- Validate that mark totals are reasonable (1-100 marks per question)\n",
    "- Use consistent formatting throughout\n",
    "\n",
    "**Document Content:**\n",
    "\n",
    "{markdown_content}\n",
    "\"\"\"\n",
    "\n",
    "            # Create configuration with structured output\n",
    "            config = types.GenerateContentConfig(\n",
    "                temperature=0.1,  # Lower temperature for more consistent extraction\n",
    "                top_p=0.5,\n",
    "                max_output_tokens=8192,  # Increased for larger documents\n",
    "                response_mime_type=\"application/json\",\n",
    "                response_schema=MarkingSchemeResponse,\n",
    "            )\n",
    "\n",
    "            # Send to Gemini using structured output\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-3-pro-preview\",\n",
    "                contents=[{\"role\": \"user\", \"parts\": [{\"text\": prompt}]}],\n",
    "                config=config,\n",
    "            )\n",
    "\n",
    "            # Enhanced response processing\n",
    "            if hasattr(response, 'parsed') and response.parsed is not None:\n",
    "                result = response.parsed\n",
    "                general_guide = result.general_grading_guide\n",
    "                questions_data = [q.model_dump() for q in result.questions]\n",
    "                \n",
    "                logger.info(f\"‚úì Successfully extracted {len(questions_data)} questions with structured output!\")\n",
    "                if general_guide:\n",
    "                    logger.info(f\"‚úì General grading guide extracted ({len(general_guide)} characters)\")\n",
    "                \n",
    "                return questions_data, general_guide\n",
    "                \n",
    "            else:\n",
    "                # Enhanced fallback to text parsing\n",
    "                response_text = response.text\n",
    "                logger.warning(\"Structured output not available, attempting text parsing\")\n",
    "                \n",
    "                try:\n",
    "                    parsed_json = json.loads(response_text)\n",
    "                    general_guide = parsed_json.get('general_grading_guide', '')\n",
    "                    questions_data = parsed_json.get('questions', [])\n",
    "                    \n",
    "                    if not questions_data:\n",
    "                        raise ValueError(\"No questions found in response\")\n",
    "                    \n",
    "                    logger.info(f\"‚úì Successfully extracted {len(questions_data)} questions from text!\")\n",
    "                    return questions_data, general_guide\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    logger.error(f\"JSON parsing failed: {e}\")\n",
    "                    if attempt < max_retries - 1:\n",
    "                        logger.info(\"Retrying with adjusted parameters...\")\n",
    "                        continue\n",
    "                    else:\n",
    "                        raise ValueError(f\"Failed to parse AI response after {max_retries} attempts\")\n",
    "                        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"AI extraction attempt {attempt + 1} failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                logger.info(\"Retrying...\")\n",
    "                continue\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "# Execute AI extraction\n",
    "try:\n",
    "    print(\"ü§ñ Processing document with Gemini AI...\")\n",
    "    questions_data, general_guide = extract_marking_scheme_with_ai(markdown_content)\n",
    "    \n",
    "    print(f\"‚úÖ AI extraction successful!\")\n",
    "    print(f\"üìä Extracted {len(questions_data)} questions\")\n",
    "    if general_guide:\n",
    "        print(f\"üìã General grading guide: {len(general_guide)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå AI extraction failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0504e269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced validation and data processing\n",
    "def validate_and_process_questions(questions_data, general_guide):\n",
    "    \"\"\"Comprehensive validation and processing of extracted questions\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Validating extracted questions...\")\n",
    "        \n",
    "        # Comprehensive validation\n",
    "        validation_errors = []\n",
    "        warnings = []\n",
    "        \n",
    "        if not questions_data:\n",
    "            validation_errors.append(\"No questions extracted from document\")\n",
    "            \n",
    "        for i, question in enumerate(questions_data):\n",
    "            q_num = question.get('question_number', f'Question {i+1}')\n",
    "            \n",
    "            # Validate required fields\n",
    "            if not question.get('question_text', '').strip():\n",
    "                validation_errors.append(f\"{q_num}: Missing question text\")\n",
    "            \n",
    "            if not question.get('marking_scheme', '').strip():\n",
    "                validation_errors.append(f\"{q_num}: Missing marking scheme\")\n",
    "            \n",
    "            # Validate marks\n",
    "            marks = question.get('marks', 0)\n",
    "            if not isinstance(marks, int) or marks <= 0:\n",
    "                validation_errors.append(f\"{q_num}: Invalid marks value ({marks})\")\n",
    "            elif marks > 50:\n",
    "                warnings.append(f\"{q_num}: High marks value ({marks}) - please verify\")\n",
    "        \n",
    "        # Report validation results\n",
    "        if validation_errors:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(colored(\"‚ùå VALIDATION ERRORS DETECTED!\", \"red\", attrs=['bold']))\n",
    "            print(\"=\"*60)\n",
    "            for error in validation_errors:\n",
    "                print(colored(f\"  ‚Ä¢ {error}\", \"red\"))\n",
    "            print(\"=\"*60)\n",
    "            raise ValueError(f\"Validation failed: {len(validation_errors)} error(s) found\")\n",
    "        \n",
    "        if warnings:\n",
    "            print(\"\\n\" + \"‚ö†Ô∏è  VALIDATION WARNINGS:\")\n",
    "            for warning in warnings:\n",
    "                print(colored(f\"  ‚Ä¢ {warning}\", \"yellow\"))\n",
    "            print()\n",
    "        \n",
    "        # Process questions - append general guide if available\n",
    "        if general_guide and general_guide.strip():\n",
    "            logger.info(\"Appending general grading guide to marking schemes\")\n",
    "            for question in questions_data:\n",
    "                question['marking_scheme'] = f\"{question['marking_scheme']}\\n\\n---\\n\\n**General Grading Guide:**\\n{general_guide}\"\n",
    "        \n",
    "        # Create DataFrame with enhanced formatting\n",
    "        df = pd.DataFrame(questions_data)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_questions = len(questions_data)\n",
    "        total_marks = df['marks'].sum()\n",
    "        avg_marks = df['marks'].mean()\n",
    "        \n",
    "        logger.info(f\"‚úì Validation passed: {total_questions} questions, {total_marks} total marks\")\n",
    "        \n",
    "        print(colored(\"‚úÖ VALIDATION SUCCESSFUL!\", \"green\", attrs=['bold']))\n",
    "        print(f\"üìä Questions: {total_questions}\")\n",
    "        print(f\"üìä Total marks: {total_marks}\")\n",
    "        print(f\"üìä Average marks per question: {avg_marks:.1f}\")\n",
    "        \n",
    "        return df, total_questions, total_marks\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Validation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute validation and processing\n",
    "try:\n",
    "    df, total_questions, total_marks = validate_and_process_questions(questions_data, general_guide)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìã Extracted Questions:\")\n",
    "    display(df[['question_number', 'question_text', 'marks']].head(10))\n",
    "    \n",
    "    if len(df) > 10:\n",
    "        print(f\"... and {len(df) - 10} more questions\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Validation failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65aa866e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced Excel export with comprehensive formatting and backup\n",
    "def create_enhanced_excel_report(df, marking_scheme_excel_file, total_questions, total_marks):\n",
    "    \"\"\"Create comprehensive Excel report with multiple sheets and formatting\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Creating Excel report: {marking_scheme_excel_file}\")\n",
    "        \n",
    "        # Create backup of existing file if it exists\n",
    "        if os.path.exists(marking_scheme_excel_file):\n",
    "            backup_file = f\"{marking_scheme_excel_file}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "            shutil.copy2(marking_scheme_excel_file, backup_file)\n",
    "            logger.info(f\"‚úì Created backup: {backup_file}\")\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(marking_scheme_excel_file), exist_ok=True)\n",
    "        \n",
    "        # Create Excel writer with multiple sheets\n",
    "        with pd.ExcelWriter(marking_scheme_excel_file, engine='openpyxl') as writer:\n",
    "            \n",
    "            # Sheet 1: Marking Scheme (detailed rubric)\n",
    "            df.to_excel(writer, sheet_name='Marking Scheme', index=False)\n",
    "            logger.info(\"‚úì Created 'Marking Scheme' sheet\")\n",
    "            \n",
    "            # Sheet 2: Summary with enhanced statistics\n",
    "            summary_data = {\n",
    "                'Metric': [\n",
    "                    'Total Questions',\n",
    "                    'Total Marks',\n",
    "                    'Average Marks per Question',\n",
    "                    'Min Marks per Question',\n",
    "                    'Max Marks per Question',\n",
    "                    'Generated On',\n",
    "                    'Input File',\n",
    "                    'Output File'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    total_questions,\n",
    "                    total_marks,\n",
    "                    f\"{df['marks'].mean():.1f}\",\n",
    "                    df['marks'].min(),\n",
    "                    df['marks'].max(),\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    os.path.basename(marking_scheme_word_file),\n",
    "                    os.path.basename(marking_scheme_excel_file)\n",
    "                ]\n",
    "            }\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            logger.info(\"‚úì Created 'Summary' sheet\")\n",
    "            \n",
    "            # Sheet 3: Question Overview (simplified view)\n",
    "            overview_df = df[['question_number', 'question_text', 'marks']].copy()\n",
    "            overview_df.to_excel(writer, sheet_name='Question Overview', index=False)\n",
    "            logger.info(\"‚úì Created 'Question Overview' sheet\")\n",
    "            \n",
    "            # Sheet 4: Validation Report\n",
    "            validation_data = {\n",
    "                'Check': [\n",
    "                    'All questions have marking schemes',\n",
    "                    'All questions have valid marks',\n",
    "                    'Question numbers are unique',\n",
    "                    'Total marks calculated',\n",
    "                    'General grading guide processed'\n",
    "                ],\n",
    "                'Status': [\n",
    "                    '‚úÖ PASS' if all(q.get('marking_scheme', '').strip() for q in questions_data) else '‚ùå FAIL',\n",
    "                    '‚úÖ PASS' if all(isinstance(q.get('marks', 0), int) and q.get('marks', 0) > 0 for q in questions_data) else '‚ùå FAIL',\n",
    "                    '‚úÖ PASS' if len(set(q.get('question_number', '') for q in questions_data)) == len(questions_data) else '‚ö†Ô∏è WARNING',\n",
    "                    f'‚úÖ PASS ({total_marks} marks)',\n",
    "                    '‚úÖ PROCESSED' if general_guide else '‚ÑπÔ∏è NOT FOUND'\n",
    "                ]\n",
    "            }\n",
    "            validation_df = pd.DataFrame(validation_data)\n",
    "            validation_df.to_excel(writer, sheet_name='Validation', index=False)\n",
    "            logger.info(\"‚úì Created 'Validation' sheet\")\n",
    "        \n",
    "        # Verify file was created successfully\n",
    "        if os.path.exists(marking_scheme_excel_file):\n",
    "            file_size = os.path.getsize(marking_scheme_excel_file)\n",
    "            logger.info(f\"‚úì Excel file created successfully ({file_size:,} bytes)\")\n",
    "            return True\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Excel file was not created\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Excel export failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute Excel export\n",
    "try:\n",
    "    success = create_enhanced_excel_report(df, marking_scheme_excel_file, total_questions, total_marks)\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(colored(\"üéâ ENHANCED STEP 2 COMPLETED SUCCESSFULLY!\", \"green\", attrs=['bold']))\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìÅ Output file: {marking_scheme_excel_file}\")\n",
    "        print(f\"üìä Questions processed: {total_questions}\")\n",
    "        print(f\"üìä Total marks: {total_marks}\")\n",
    "        print(f\"üìã Sheets created: Marking Scheme, Summary, Question Overview, Validation\")\n",
    "        print(f\"‚è∞ Processing completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\n‚úÖ Ready for Step 3: Question Annotations\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Excel export failed: {e}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
