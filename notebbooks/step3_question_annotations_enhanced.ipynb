{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Answer Bounding Boxes (Enhanced)\n",
    "1. Convert the exam PDF into page images.\n",
    "2. Auto-detect bounding boxes with AI.\n",
    "3. Manually review and adjust each answer region.\n",
    "\n",
    "**Enhancements:**\n",
    "- ‚úÖ Comprehensive validation of input files and setup\n",
    "- ‚úÖ Enhanced OCR processing with retry logic and caching\n",
    "- ‚úÖ Progress tracking for multi-page processing\n",
    "- ‚úÖ Coordinate validation and scaling\n",
    "- ‚úÖ Robust error handling and recovery\n",
    "- ‚úÖ Detailed processing reports and validation summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup validation passed\n"
     ]
    }
   ],
   "source": [
    "from grading_utils import (\n",
    "    setup_paths, create_directories, init_gemini_client, \n",
    "    validate_required_files, print_validation_summary\n",
    ")\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "prefix = \"VTC Test\"\n",
    "paths = setup_paths(prefix, \"sample\")\n",
    "\n",
    "# Validate required files exist\n",
    "missing_files = validate_required_files(paths)\n",
    "if missing_files:\n",
    "    print(\"‚ùå Setup validation failed!\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  Missing: {file}\")\n",
    "    raise FileNotFoundError(\"Please ensure all required files are present.\")\n",
    "\n",
    "pdf_file = paths[\"pdf_file\"]\n",
    "\n",
    "# Configuration - can be adjusted for testing\n",
    "number_of_pages = 2  # Set to specific number for testing, or use len(pages) after conversion\n",
    "\n",
    "print(\"‚úÖ Setup validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:07:32,784 - INFO - ‚úì Created all necessary directories\n",
      "2026-01-04 20:07:32,785 - INFO - Converting PDF to images...\n",
      "2026-01-04 20:07:33,471 - INFO - ‚úì Converted PDF to 8 images in 0.69s\n",
      "Saving images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 61.37it/s]\n",
      "2026-01-04 20:07:33,606 - INFO - ‚úì Saved 8 images to ../marking_form/VTC Test/images/\n"
     ]
    }
   ],
   "source": [
    "# Enhanced directory creation and PDF conversion\n",
    "try:\n",
    "    # Extract paths from setup\n",
    "    file_name = paths[\"file_name\"]\n",
    "    base_path = paths[\"base_path\"]\n",
    "    base_path_images = paths[\"base_path_images\"]\n",
    "    base_path_annotations = paths[\"base_path_annotations\"]\n",
    "\n",
    "    # Create directories with error handling\n",
    "    create_directories(paths)\n",
    "    logger.info(\"‚úì Created all necessary directories\")\n",
    "\n",
    "    # Convert PDF to images with progress tracking\n",
    "    logger.info(\"Converting PDF to images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pages = convert_from_path(pdf_file, fmt='jpeg')\n",
    "    conversion_time = time.time() - start_time\n",
    "    \n",
    "    logger.info(f\"‚úì Converted PDF to {len(pages)} images in {conversion_time:.2f}s\")\n",
    "    \n",
    "    # Save images with progress tracking\n",
    "    for count, page in enumerate(tqdm(pages, desc=\"Saving images\")):\n",
    "        image_path = f'{base_path_images}{count}.jpg'\n",
    "        page.save(image_path, 'JPEG')\n",
    "    \n",
    "    logger.info(f\"‚úì Saved {len(pages)} images to {base_path_images}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to convert PDF or create directories: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# Enhanced utility functions with error handling\n",
    "def update_json_file(annotations, path):\n",
    "    \"\"\"Update JSON file with error handling.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(annotations, f, indent=4)\n",
    "        logger.info(f\"‚úì Updated annotations file: {path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to update JSON file {path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def image_to_data_url(filename):\n",
    "    \"\"\"Convert image to data URL with error handling.\"\"\"\n",
    "    try:\n",
    "        ext = filename.split(\".\")[-1].lower()\n",
    "        if ext == 'jpg':\n",
    "            ext = 'jpeg'\n",
    "        prefix = f\"data:image/{ext};base64,\"\n",
    "        \n",
    "        with open(filename, \"rb\") as f:\n",
    "            img = f.read()\n",
    "        return prefix + base64.b64encode(img).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert image to data URL {filename}: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úì Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:07:33,676 - INFO - ‚úÖ Gemini client initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Vertex AI Express Mode initialized\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Gemini client initialization\n",
    "try:\n",
    "    client = init_gemini_client()\n",
    "    logger.info(\"‚úÖ Gemini client initialized successfully\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to initialize Gemini client: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pydantic models defined for structured output\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Pydantic models with validation\n",
    "class BoundingBox(BaseModel):\n",
    "    \"\"\"Represents a single bounding box annotation with validation.\"\"\"\n",
    "    x: int = Field(description=\"X coordinate of the top-left corner\", ge=0)\n",
    "    y: int = Field(description=\"Y coordinate of the top-left corner\", ge=0)\n",
    "    width: int = Field(description=\"Width of the bounding box\", gt=0)\n",
    "    height: int = Field(description=\"Height of the bounding box\", gt=0)\n",
    "    label: str = Field(description=\"Question number (e.g., '1', '2', '3')\", min_length=1)\n",
    "\n",
    "class BoundingBoxResponse(BaseModel):\n",
    "    \"\"\"Wrapper class for list of bounding boxes with validation.\"\"\"\n",
    "    boxes: List[BoundingBox] = Field(description=\"List of bounding boxes for question cells\")\n",
    "\n",
    "logger.info(\"‚úì Pydantic models defined for structured output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:07:33,741 - INFO - ‚úì Enhanced OCR function defined\n"
     ]
    }
   ],
   "source": [
    "# Enhanced OCR function with retry logic and caching\n",
    "from grading_utils import get_cache_key, get_from_cache, save_to_cache, create_gemini_config\n",
    "\n",
    "def ocr_structured_enhanced(prompt: str, filePath: str, response_schema: BaseModel, max_retries: int = 3):\n",
    "    \"\"\"\n",
    "    Enhanced OCR function with caching, retry logic, and comprehensive error handling.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The prompt describing what to extract\n",
    "        filePath: Path to the image file\n",
    "        response_schema: Pydantic BaseModel class defining the expected response structure\n",
    "        max_retries: Maximum number of retry attempts\n",
    "    \n",
    "    Returns:\n",
    "        Parsed response as the specified Pydantic model\n",
    "    \"\"\"\n",
    "    # Generate cache key\n",
    "    cache_key = get_cache_key(\"ocr_structured\", file=filePath, prompt_hash=hash(prompt))\n",
    "    \n",
    "    # Try to get from cache first\n",
    "    cached_result = get_from_cache(cache_key)\n",
    "    if cached_result:\n",
    "        logger.info(f\"‚úì Using cached result for {filePath}\")\n",
    "        try:\n",
    "            return response_schema(**cached_result)\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Failed to parse cached result: {e}\")\n",
    "    \n",
    "    # Read the image file\n",
    "    try:\n",
    "        with open(filePath, \"rb\") as f:\n",
    "            data = f.read()\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to read image file {filePath}: {e}\")\n",
    "        return response_schema(boxes=[])\n",
    "    \n",
    "    # Create configuration with structured output\n",
    "    config = create_gemini_config(\n",
    "        temperature=0,\n",
    "        top_p=0.5,\n",
    "        max_output_tokens=65535,\n",
    "        response_mime_type=\"application/json\",\n",
    "        response_schema=response_schema\n",
    "    )\n",
    "    \n",
    "    # Retry logic\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            logger.info(f\"OCR attempt {attempt + 1}/{max_retries} for {filePath}\")\n",
    "            \n",
    "            # Generate content with structured output\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-3-flash-preview\",\n",
    "                contents=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [\n",
    "                            {\"inline_data\": {\"mime_type\": \"image/jpeg\", \"data\": data}},\n",
    "                            {\"text\": prompt}\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                config=config,\n",
    "            )\n",
    "            \n",
    "            # Try to use parsed property first\n",
    "            if hasattr(response, 'parsed') and response.parsed is not None:\n",
    "                result = response.parsed\n",
    "                logger.info(f\"‚úì Response parsed successfully - found {len(result.boxes)} boxes\")\n",
    "                \n",
    "                # Cache the result\n",
    "                save_to_cache(cache_key, result.model_dump())\n",
    "                return result\n",
    "            \n",
    "            # Fall back to text-based parsing\n",
    "            if response.text:\n",
    "                import json\n",
    "                result_dict = json.loads(response.text)\n",
    "                result = response_schema(**result_dict)\n",
    "                logger.info(f\"‚úì Successfully parsed {len(result.boxes)} boxes from text\")\n",
    "                \n",
    "                # Cache the result\n",
    "                save_to_cache(cache_key, result.model_dump())\n",
    "                return result\n",
    "            \n",
    "            logger.warning(f\"Empty response received for {filePath} on attempt {attempt + 1}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"OCR attempt {attempt + 1} failed for {filePath}: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                logger.error(f\"All OCR attempts failed for {filePath}\")\n",
    "                return response_schema(boxes=[])\n",
    "            \n",
    "            # Wait before retry\n",
    "            time.sleep(2 ** attempt)  # Exponential backoff\n",
    "    \n",
    "    return response_schema(boxes=[])\n",
    "\n",
    "logger.info(\"‚úì Enhanced OCR function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting enhanced bounding box extraction...\n",
      "Processing 2 pages with enhanced OCR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   0%|          | 0/2 [00:00<?, ?it/s]2026-01-04 20:07:33,766 - INFO - OCR attempt 1/3 for ../marking_form/VTC Test/images/0.jpg\n",
      "2026-01-04 20:07:33,767 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing page 0 (../marking_form/VTC Test/images/0.jpg)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:08:04,579 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 20:08:04,581 - INFO - ‚úì Response parsed successfully - found 6 boxes\n",
      "Processing pages:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:30<00:30, 30.82s/it]2026-01-04 20:08:04,583 - INFO - OCR attempt 1/3 for ../marking_form/VTC Test/images/1.jpg\n",
      "2026-01-04 20:08:04,584 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Page 0: Found 6 bounding boxes\n",
      "[\n",
      "  {\n",
      "    \"x\": 133,\n",
      "    \"y\": 260,\n",
      "    \"width\": 719,\n",
      "    \"height\": 110,\n",
      "    \"label\": \"Q1\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 133,\n",
      "    \"y\": 370,\n",
      "    \"width\": 719,\n",
      "    \"height\": 124,\n",
      "    \"label\": \"Q2\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 133,\n",
      "    \"y\": 494,\n",
      "    \"width\": 719,\n",
      "    \"height\": 108,\n",
      "    \"label\": \"Q3\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 205,\n",
      "    \"y\": 205,\n",
      "    \"width\": 370,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"NAME\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 705,\n",
      "    \"y\": 205,\n",
      "    \"width\": 120,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"ID\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 205,\n",
      "    \"y\": 235,\n",
      "    \"width\": 370,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"CLASS\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "Processing page 1 (../marking_form/VTC Test/images/1.jpg)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:08:32,514 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-04 20:08:32,516 - INFO - ‚úì Response parsed successfully - found 5 boxes\n",
      "Processing pages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:58<00:00, 29.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Page 1: Found 5 bounding boxes\n",
      "[\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 178,\n",
      "    \"width\": 132,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"NAME\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 584,\n",
      "    \"y\": 178,\n",
      "    \"width\": 241,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"ID\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 205,\n",
      "    \"width\": 83,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"CLASS\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 234,\n",
      "    \"width\": 719,\n",
      "    \"height\": 111,\n",
      "    \"label\": \"4\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 345,\n",
      "    \"width\": 719,\n",
      "    \"height\": 123,\n",
      "    \"label\": \"5\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "‚úÖ ENHANCED BOUNDING BOX EXTRACTION COMPLETED!\n",
      "============================================================\n",
      "üìä Processing Statistics:\n",
      "   Total pages: 2\n",
      "   Successful: 2\n",
      "   Failed: 0\n",
      "   Total boxes found: 11\n",
      "   Processing time: 58.75s\n",
      "   Average per page: 29.38s\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Enhanced bounding box extraction with comprehensive processing\n",
    "import json\n",
    "import copy\n",
    "\n",
    "# Enhanced prompt for better extraction\n",
    "prompt = \"\"\"Extract the coordinates of bounding boxes for each question/answer cell from the table in the image.\n",
    "\n",
    "Instructions:\n",
    "- Identify all table cells that contain question numbers (like \"1\", \"2\", \"3\", \"4\", \"5\", etc.)\n",
    "- Question numbers are typically located in the top-left corner or top area of each cell\n",
    "- Each bounding box should cover the entire cell area where a student would write their answer\n",
    "- Include cells with sub-questions (like 22a, 22b, 22c, etc.) as separate bounding boxes\n",
    "- Do NOT include cells that only contain \"XXXXXXX\" or are marked as non-answer areas\n",
    "- Bounding boxes may be adjacent but should not overlap\n",
    "- For merged cells spanning multiple rows/columns, create one bounding box covering the entire merged area\n",
    "- Also identify and mark special fields: NAME, ID, CLASS (student information fields)\n",
    "\n",
    "For each bounding box, provide:\n",
    "- x: X coordinate of the top-left corner of the cell\n",
    "- y: Y coordinate of the top-left corner of the cell\n",
    "- width: Width of the entire cell (including answer space)\n",
    "- height: Height of the entire cell (including answer space)\n",
    "- label: The question number or field name (e.g., \"1\", \"2\", \"3\", \"NAME\", \"ID\", \"CLASS\")\n",
    "\n",
    "Important: \n",
    "- Extract the question number text exactly as shown (including letters like \"a\", \"b\", \"c\" for sub-questions)\n",
    "- Do not include the period after the question number in the label\n",
    "- Focus on cells where students write answers, not header cells or instruction text\n",
    "- Ensure NAME, ID, and CLASS fields are properly identified for student information\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç Starting enhanced bounding box extraction...\")\n",
    "print(f\"Processing {number_of_pages} pages with enhanced OCR\")\n",
    "\n",
    "aiAnnotation = {}\n",
    "processing_stats = {\n",
    "    'total_pages': number_of_pages,\n",
    "    'successful_pages': 0,\n",
    "    'failed_pages': 0,\n",
    "    'total_boxes': 0,\n",
    "    'processing_time': 0\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each page with progress tracking\n",
    "for i in tqdm(range(number_of_pages), desc=\"Processing pages\"):\n",
    "    image_path = base_path_images + f\"{i}.jpg\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing page {i} ({image_path})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Validate image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Use enhanced OCR with retry logic\n",
    "        result = ocr_structured_enhanced(prompt, image_path, BoundingBoxResponse)\n",
    "        \n",
    "        # Convert Pydantic model to dict and extract boxes\n",
    "        boxes_dict = [box.model_dump() for box in result.boxes]\n",
    "        aiAnnotation[str(i)] = boxes_dict\n",
    "        \n",
    "        processing_stats['successful_pages'] += 1\n",
    "        processing_stats['total_boxes'] += len(boxes_dict)\n",
    "        \n",
    "        print(f\"‚úì Page {i}: Found {len(boxes_dict)} bounding boxes\")\n",
    "        if boxes_dict:\n",
    "            print(json.dumps(boxes_dict, indent=2))\n",
    "            \n",
    "            # Validate bounding boxes\n",
    "            for box in boxes_dict:\n",
    "                if box['width'] <= 0 or box['height'] <= 0:\n",
    "                    logger.warning(f\"Invalid box dimensions on page {i}: {box}\")\n",
    "        else:\n",
    "            print(\"  (No bounding boxes detected)\")\n",
    "            logger.warning(f\"No bounding boxes found on page {i}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process page {i}: {type(e).__name__}: {e}\")\n",
    "        aiAnnotation[str(i)] = []\n",
    "        processing_stats['failed_pages'] += 1\n",
    "\n",
    "processing_stats['processing_time'] = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ ENHANCED BOUNDING BOX EXTRACTION COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìä Processing Statistics:\")\n",
    "print(f\"   Total pages: {processing_stats['total_pages']}\")\n",
    "print(f\"   Successful: {processing_stats['successful_pages']}\")\n",
    "print(f\"   Failed: {processing_stats['failed_pages']}\")\n",
    "print(f\"   Total boxes found: {processing_stats['total_boxes']}\")\n",
    "print(f\"   Processing time: {processing_stats['processing_time']:.2f}s\")\n",
    "print(f\"   Average per page: {processing_stats['processing_time']/number_of_pages:.2f}s\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "backup = copy.deepcopy(aiAnnotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:09:18,215 - INFO - ‚úì Image dimensions: 1654x2338\n",
      "2026-01-04 20:09:18,216 - INFO - Scaling factors: x=1.654, y=2.338\n",
      "2026-01-04 20:09:18,217 - INFO - ‚úì Saved AI annotations to: ../marking_form/VTC Test/annotations/ai_annotations.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: Width: 1654, Height: 2338\n",
      "\n",
      "üìê Coordinate Scaling Results:\n",
      "   Successfully scaled: 11 boxes\n",
      "   Invalid after scaling: 0 boxes\n",
      "‚úì AI annotations saved to: ../marking_form/VTC Test/annotations/ai_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# Enhanced coordinate scaling and validation\n",
    "from PIL import Image\n",
    "\n",
    "# Get image dimensions for scaling\n",
    "sample_image_path = base_path_images + \"0.jpg\"\n",
    "try:\n",
    "    with Image.open(sample_image_path) as img:\n",
    "        width, height = img.size\n",
    "    \n",
    "    logger.info(f\"‚úì Image dimensions: {width}x{height}\")\n",
    "    print(f\"Image dimensions: Width: {width}, Height: {height}\")\n",
    "    \n",
    "    # Calculate scaling factors\n",
    "    x_scale = width / 1000.0\n",
    "    y_scale = height / 1000.0\n",
    "    \n",
    "    logger.info(f\"Scaling factors: x={x_scale:.3f}, y={y_scale:.3f}\")\n",
    "    \n",
    "    # Apply scaling with validation\n",
    "    aiAnnotation = copy.deepcopy(backup)\n",
    "    scaling_stats = {'scaled_boxes': 0, 'invalid_boxes': 0}\n",
    "    \n",
    "    for i in range(number_of_pages):\n",
    "        for item in aiAnnotation[str(i)]:\n",
    "            # Store original values for validation\n",
    "            orig_x, orig_y = item['x'], item['y']\n",
    "            orig_w, orig_h = item['width'], item['height']\n",
    "            \n",
    "            # Apply scaling\n",
    "            item['x'] = int(round(item['x'] * x_scale))\n",
    "            item['y'] = int(round(item['y'] * y_scale))\n",
    "            item['width'] = int(round(item['width'] * x_scale))\n",
    "            item['height'] = int(round(item['height'] * y_scale))\n",
    "            \n",
    "            # Validate scaled coordinates\n",
    "            if (item['x'] < 0 or item['y'] < 0 or \n",
    "                item['x'] + item['width'] > width or \n",
    "                item['y'] + item['height'] > height):\n",
    "                logger.warning(f\"Scaled box out of bounds on page {i}: {item}\")\n",
    "                scaling_stats['invalid_boxes'] += 1\n",
    "            else:\n",
    "                scaling_stats['scaled_boxes'] += 1\n",
    "    \n",
    "    print(f\"\\nüìê Coordinate Scaling Results:\")\n",
    "    print(f\"   Successfully scaled: {scaling_stats['scaled_boxes']} boxes\")\n",
    "    print(f\"   Invalid after scaling: {scaling_stats['invalid_boxes']} boxes\")\n",
    "    \n",
    "    # Save AI annotations\n",
    "    ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "    \n",
    "    with open(ai_annotations_path, \"w\") as f:\n",
    "        json.dump(aiAnnotation, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"‚úì Saved AI annotations to: {ai_annotations_path}\")\n",
    "    print(f\"‚úì AI annotations saved to: {ai_annotations_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process image dimensions or scaling: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Annotation Review and Adjustment\n",
    "\n",
    "Please ensure the following are clearly marked on each page before grading:\n",
    "- **ID**: Student identification number\n",
    "- **NAME**: Student name field\n",
    "- **CLASS**: Student class/section\n",
    "\n",
    "Use the interactive widget below to review and adjust the AI-generated bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 20:09:20,219 - INFO - Found 8 image files for annotation\n",
      "2026-01-04 20:09:20,221 - INFO - ‚úì Loaded AI annotations for 2 pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded AI annotations for 2 pages\n",
      "Total pages with annotations: ['0', '1']\n",
      "\n",
      "üéØ Interactive annotation widget ready!\n",
      "Use the widget below to review and adjust bounding boxes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e4db1cfa354cccb78c38236183ca80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìù Enhanced Interactive Annotation Tool</h3>'), HTML(value='<b>Status:</b> Loade‚Ä¶"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enhanced interactive annotation widget with comprehensive features\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import ipywidgets as widgets\n",
    "import glob\n",
    "\n",
    "# Initialize widget state\n",
    "page = 1\n",
    "pageAndBoundingBoxes = {}\n",
    "\n",
    "# Get all image files\n",
    "files = sorted(glob.glob(base_path_images + \"*.jpg\"))\n",
    "logger.info(f\"Found {len(files)} image files for annotation\")\n",
    "\n",
    "# Create progress widget\n",
    "w_progress = widgets.IntProgress(\n",
    "    value=0, \n",
    "    max=len(files), \n",
    "    description=\"Progress\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# File paths\n",
    "annotations_path = base_path_annotations + \"annotations.json\"\n",
    "ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "\n",
    "# Load existing annotations with priority: manual > AI\n",
    "annotations = {}\n",
    "\n",
    "# Load AI annotations first (as base)\n",
    "if os.path.exists(ai_annotations_path):\n",
    "    try:\n",
    "        with open(ai_annotations_path, \"r\") as f: \n",
    "            annotations = json.load(f)\n",
    "        logger.info(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "        print(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load AI annotations: {e}\")\n",
    "\n",
    "# Then merge/override with manual annotations if they exist\n",
    "if os.path.exists(annotations_path):\n",
    "    try:\n",
    "        with open(annotations_path, \"r\") as f: \n",
    "            manual_annotations = json.load(f)\n",
    "            annotations.update(manual_annotations)  # Manual annotations take priority\n",
    "        logger.info(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "        print(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load manual annotations: {e}\")\n",
    "\n",
    "print(f\"Total pages with annotations: {list(annotations.keys())}\")\n",
    "\n",
    "# Create question input widget\n",
    "question_widget = widgets.Text(\n",
    "    value=\"\", \n",
    "    placeholder=\"Enter question label (e.g., '1', '2', 'NAME', 'ID')\", \n",
    "    description=\"Question:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create status widget\n",
    "status_widget = widgets.HTML(\n",
    "    value=\"<b>Status:</b> Ready to annotate\",\n",
    "    description=\"\"\n",
    ")\n",
    "\n",
    "# Create bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image=image_to_data_url(files[0]) if files else None\n",
    ")\n",
    "w_bbox.attach(question_widget, name=\"label\")\n",
    "\n",
    "# Load initial bounding boxes\n",
    "initial_page = str(w_progress.value)\n",
    "if initial_page in annotations:\n",
    "    w_bbox.bboxes = annotations[initial_page]\n",
    "    status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[initial_page])} boxes for page {w_progress.value}\"\n",
    "else:\n",
    "    w_bbox.bboxes = []\n",
    "    status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "\n",
    "# Enhanced skip function\n",
    "def on_skip():\n",
    "    if w_progress.value + 1 >= len(files):\n",
    "        status_widget.value = f\"<b>Status:</b> Already at the last page ({len(files)-1})\"\n",
    "        logger.info(f\"Already at the last page ({len(files)-1})\")\n",
    "        return\n",
    "    \n",
    "    w_progress.value += 1\n",
    "    current_page = str(w_progress.value)\n",
    "    \n",
    "    try:\n",
    "        # Load new image in the widget\n",
    "        image_file = files[w_progress.value]\n",
    "        w_bbox.image = image_to_data_url(image_file)\n",
    "        \n",
    "        # Load bounding boxes for current page\n",
    "        if current_page in annotations:\n",
    "            w_bbox.bboxes = annotations[current_page]\n",
    "            status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[current_page])} boxes for page {w_progress.value}\"\n",
    "            logger.info(f\"‚úì Loaded {len(annotations[current_page])} bounding boxes for page {w_progress.value}\")\n",
    "        else:\n",
    "            w_bbox.bboxes = []\n",
    "            status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "            logger.warning(f\"‚ö†Ô∏è No annotations found for page {w_progress.value}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error loading page {w_progress.value}: {e}\"\n",
    "        logger.error(f\"Error loading page {w_progress.value}: {e}\")\n",
    "\n",
    "w_bbox.on_skip(on_skip)\n",
    "\n",
    "# Enhanced submit function\n",
    "def on_submit():\n",
    "    try:\n",
    "        current_page = str(w_progress.value)\n",
    "        \n",
    "        # Save annotations for current image\n",
    "        annotations[current_page] = w_bbox.bboxes\n",
    "        update_json_file(annotations, annotations_path)\n",
    "        \n",
    "        status_widget.value = f\"<b>Status:</b> Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\"\n",
    "        logger.info(f\"‚úì Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\")\n",
    "        \n",
    "        # Move to next page\n",
    "        on_skip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error saving annotations: {e}\"\n",
    "        logger.error(f\"Error saving annotations: {e}\")\n",
    "\n",
    "w_bbox.on_submit(on_submit)\n",
    "\n",
    "# Output widget for bbox changes\n",
    "w_out = widgets.Output()\n",
    "\n",
    "def on_bbox_change(change):\n",
    "    w_out.clear_output(wait=True)\n",
    "    with w_out:\n",
    "        current_boxes = change[\"new\"]\n",
    "        print(f\"Page {w_progress.value}: {len(current_boxes)} bounding boxes\")\n",
    "        if current_boxes:\n",
    "            print(json.dumps(current_boxes, indent=2))\n",
    "        pageAndBoundingBoxes[w_progress.value] = current_boxes\n",
    "\n",
    "w_bbox.observe(on_bbox_change, names=[\"bboxes\"])\n",
    "\n",
    "# Create comprehensive widget container\n",
    "w_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üìù Enhanced Interactive Annotation Tool</h3>\"),\n",
    "    status_widget,\n",
    "    widgets.HBox([\n",
    "        question_widget,\n",
    "        widgets.HTML(\"<i>Tip: Use 'NAME', 'ID', 'CLASS' for student info fields</i>\")\n",
    "    ]),\n",
    "    w_progress,\n",
    "    w_bbox,\n",
    "    widgets.HTML(\"<b>Current Annotations:</b>\"),\n",
    "    w_out,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='margin-top: 10px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;'>\n",
    "    <b>Instructions:</b><br>\n",
    "    ‚Ä¢ Draw bounding boxes around answer areas<br>\n",
    "    ‚Ä¢ Label each box with question number or field name<br>\n",
    "    ‚Ä¢ Use 'Submit' to save and move to next page<br>\n",
    "    ‚Ä¢ Use 'Skip' to move without saving<br>\n",
    "    ‚Ä¢ Ensure NAME, ID, and CLASS fields are marked\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "print(\"\\nüéØ Interactive annotation widget ready!\")\n",
    "print(\"Use the widget below to review and adjust bounding boxes.\")\n",
    "\n",
    "w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ ENHANCED STEP 3: ANNOTATION EXTRACTION COMPLETED\n",
      "======================================================================\n",
      "üìä Annotation Statistics:\n",
      "   Total pages annotated: 2\n",
      "   Total bounding boxes: 8\n",
      "   Average boxes per page: 4.0\n",
      "\n",
      "üè∑Ô∏è Label Distribution:\n",
      "   CLASS: 1 boxes\n",
      "   ID: 1 boxes\n",
      "   NAME: 1 boxes\n",
      "   Q1: 1 boxes\n",
      "   Q2: 1 boxes\n",
      "   Q3: 1 boxes\n",
      "   Q4: 1 boxes\n",
      "   Q5: 1 boxes\n",
      "\n",
      "‚úÖ Required Field Coverage:\n",
      "   ‚úì NAME: Found on 1/2 pages\n",
      "   ‚úì ID: Found on 1/2 pages\n",
      "   ‚úì CLASS: Found on 1/2 pages\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   ‚úÖ AI annotations: ../marking_form/VTC Test/annotations/ai_annotations.json\n",
      "   ‚úÖ Final annotations: ../marking_form/VTC Test/annotations/annotations.json\n",
      "   ‚úÖ Page images: ../marking_form/VTC Test/images/ (8 files)\n",
      "\n",
      "üéØ Next Steps:\n",
      "   ‚úÖ All required fields present - ready for Step 4\n",
      "   1. Proceed to Step 4: Scoring Preprocessing\n",
      "   2. The annotations will be used for answer extraction\n",
      "\n",
      "üí° Quality Assurance:\n",
      "   ‚Ä¢ Enhanced OCR with retry logic and caching\n",
      "   ‚Ä¢ Comprehensive coordinate validation and scaling\n",
      "   ‚Ä¢ Interactive review and adjustment capability\n",
      "   ‚Ä¢ Detailed processing statistics and error handling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Enhanced Step 3 completed successfully!\n",
      "Ready for answer extraction and grading!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final enhanced summary and validation\n",
    "def generate_annotation_summary():\n",
    "    \"\"\"Generate comprehensive annotation summary and validation report.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üéâ ENHANCED STEP 3: ANNOTATION EXTRACTION COMPLETED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load final annotations\n",
    "    final_annotations = {}\n",
    "    if os.path.exists(annotations_path):\n",
    "        with open(annotations_path, \"r\") as f:\n",
    "            final_annotations = json.load(f)\n",
    "    \n",
    "    # Generate statistics\n",
    "    total_pages = len(final_annotations)\n",
    "    total_boxes = sum(len(boxes) for boxes in final_annotations.values())\n",
    "    \n",
    "    # Analyze annotation types\n",
    "    label_counts = {}\n",
    "    required_fields = ['NAME', 'ID', 'CLASS']\n",
    "    pages_with_required = {field: 0 for field in required_fields}\n",
    "    \n",
    "    for page, boxes in final_annotations.items():\n",
    "        page_labels = set()\n",
    "        for box in boxes:\n",
    "            label = box.get('label', 'Unknown')\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "            page_labels.add(label)\n",
    "        \n",
    "        # Check for required fields\n",
    "        for field in required_fields:\n",
    "            if field in page_labels:\n",
    "                pages_with_required[field] += 1\n",
    "    \n",
    "    print(f\"üìä Annotation Statistics:\")\n",
    "    print(f\"   Total pages annotated: {total_pages}\")\n",
    "    print(f\"   Total bounding boxes: {total_boxes}\")\n",
    "    print(f\"   Average boxes per page: {total_boxes/total_pages:.1f}\" if total_pages > 0 else \"   No pages annotated\")\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Label Distribution:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"   {label}: {count} boxes\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Required Field Coverage:\")\n",
    "    all_required_present = True\n",
    "    for field in required_fields:\n",
    "        coverage = pages_with_required[field]\n",
    "        status = \"‚úì\" if coverage > 0 else \"‚ùå\"\n",
    "        print(f\"   {status} {field}: Found on {coverage}/{total_pages} pages\")\n",
    "        if coverage == 0:\n",
    "            all_required_present = False\n",
    "    \n",
    "    print(f\"\\nüìÅ Generated Files:\")\n",
    "    print(f\"   ‚úÖ AI annotations: {ai_annotations_path}\")\n",
    "    print(f\"   ‚úÖ Final annotations: {annotations_path}\")\n",
    "    print(f\"   ‚úÖ Page images: {base_path_images} ({len(files)} files)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    if all_required_present:\n",
    "        print(f\"   ‚úÖ All required fields present - ready for Step 4\")\n",
    "        print(f\"   1. Proceed to Step 4: Scoring Preprocessing\")\n",
    "        print(f\"   2. The annotations will be used for answer extraction\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Missing required fields - please review annotations\")\n",
    "        print(f\"   1. Use the annotation widget to add missing NAME/ID/CLASS fields\")\n",
    "        print(f\"   2. Ensure all pages have student identification fields\")\n",
    "        print(f\"   3. Then proceed to Step 4\")\n",
    "    \n",
    "    print(f\"\\nüí° Quality Assurance:\")\n",
    "    print(f\"   ‚Ä¢ Enhanced OCR with retry logic and caching\")\n",
    "    print(f\"   ‚Ä¢ Comprehensive coordinate validation and scaling\")\n",
    "    print(f\"   ‚Ä¢ Interactive review and adjustment capability\")\n",
    "    print(f\"   ‚Ä¢ Detailed processing statistics and error handling\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ Enhanced Step 3 completed successfully!\")\n",
    "    print(\"Ready for answer extraction and grading!\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "# Generate the summary\n",
    "generate_annotation_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
