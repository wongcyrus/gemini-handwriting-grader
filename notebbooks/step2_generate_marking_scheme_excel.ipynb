{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d61b374",
   "metadata": {},
   "source": [
    "# Step 2: Extract Marking Scheme to Excel\n",
    "\n",
    "Use Gemini to parse the Word marking scheme into structured Excel sheets with error handling, validation, and progress tracking.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Comprehensive error handling and validation\n",
    "- ‚úÖ Robust progress tracking and logging\n",
    "- ‚úÖ Improved markdown formatting and structure\n",
    "- ‚úÖ Robust file handling and backup\n",
    "- ‚úÖ Detailed validation and quality checks\n",
    "- ‚úÖ Professional output formatting\n",
    "\n",
    "Configure the exam `prefix` and dataset folder in the next cell before running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f987fbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b' 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Sa']\n",
      "Bad pipe message: %s [b'ri/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/', b'ng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nAccept-Encoding: gzip, deflate, br, zstd\\r\\nA']\n",
      "Bad pipe message: %s [b'ept-Language: en-US,en;q=0.9,zh-TW;q=0.8,zh;q=0.7\\r\\nPriority: u=0, i\\r\\nReferer: https://studio.fireb', b'e.google.com/\\r\\nSec-Ch-Ua: \"Google Chrome\";v=\"143\", \"Chromium\";v=\"143\", \"Not A(Brand\";v=\"24\"\\r\\nSec', b'h-Ua-Arch: \"x86\"\\r\\nSec-Ch-Ua-Bitness: \"64\"\\r\\nS', b'-Ch-Ua-Form-Factors: \"Desktop\"\\r\\nSec-Ch-Ua-Full-Version: \"143.0.7499.170\"\\r\\nSec-Ch-Ua-Full-Version-Lis', b' \"Google Chrome\";v=\"143.0.7499.170\", \"Chromium\";v=\"143.0.7499.170\", \"Not A(Brand\";v=\"24.0.0.0\"\\r\\nSec-Ch-Ua-Mobile: ?']\n",
      "Bad pipe message: %s [b'\\nSec-Ch-Ua-Model: \"\"\\r\\nSec-Ch-Ua-Platform: \"Wind', b's\"\\r\\nSec-Ch-Ua-Platform-Version: \"19.0.0\"\\r\\nSec-Ch-Ua-Wow64: ?0\\r\\nSec-Fetch-Dest: iframe\\r\\nSec-Fetch-Mode: navigat', b'\\nSec-Fetch-Site: cross-site\\r\\nSec-Fetch-Storage-Access: active\\r\\nSec-Fetch-User: ?1\\r\\nSec-User-Ip: 10.2', b'20.217\\r\\nUpgrade-Insecure-Requests: 1\\r\\nX-Forward']\n",
      "Bad pipe message: %s [b'-Host: 41333-firebase-gemini-ai-grader-1767589248216.cluster-ejd22kqny5htuv5dfowoyipt52.cloudworksta']\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 577, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 993, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 577, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 993, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 577, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 993, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 577, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 993, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/zmq/eventloop/zmqstream.py\", line 565, in _log_error\n",
      "    f.result()\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 577, in shell_channel_thread_main\n",
      "    _, msg2 = self.session.feed_identities(msg, copy=False)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/gemini-handwriting-grader/.venv/lib/python3.12/site-packages/jupyter_client/session.py\", line 993, in feed_identities\n",
      "    raise ValueError(msg)\n",
      "ValueError: DELIM not in msg_list\n",
      "2026-01-07 14:18:59,004 - INFO - Mapped GOOGLE_GENAI_API_KEY to GOOGLE_API_KEY for ADK\n",
      "2026-01-07 14:19:01,565 - INFO - ‚úì Input file validated: ../sample/VTC Test Marking Scheme.docx\n",
      "2026-01-07 14:19:01,567 - INFO - ‚úì Output file will be: ../sample/VTC Test Marking Scheme.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Robust Step 2: Extract Marking Scheme to Excel initialized\n",
      "‚úì Session started at: 2026-01-07 14:19:01\n",
      "üìÅ Input: ../sample/VTC Test Marking Scheme.docx\n",
      "üìÅ Output: ../sample/VTC Test Marking Scheme.xlsx\n"
     ]
    }
   ],
   "source": [
    "from grading_utils import setup_paths, init_gemini_client\n",
    "from agents.marking_scheme_agent.agent import extract_marking_scheme_with_ai, verify_marking_scheme_with_ai\n",
    "from google.genai import types\n",
    "import mammoth\n",
    "import html2text\n",
    "from IPython.display import Markdown, display, clear_output\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json\n",
    "import pandas as pd\n",
    "from termcolor import colored\n",
    "import os\n",
    "import shutil\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import docx\n",
    "from docx import Document\n",
    "from docx.shared import RGBColor\n",
    "from docx.enum.dml import MSO_THEME_COLOR_INDEX\n",
    "import re\n",
    "\n",
    "def add_hyperlink(paragraph, text, url):\n",
    "    \"\"\"Adds a clickable hyperlink to a paragraph\"\"\"\n",
    "    # This gets access to the document.xml.rels file and gets a new relation id\n",
    "    part = paragraph.part\n",
    "    r_id = part.relate_to(url, docx.opc.constants.RELATIONSHIP_TYPE.HYPERLINK, is_external=True)\n",
    "\n",
    "    # Create the w:hyperlink tag and add needed values\n",
    "    hyperlink = docx.oxml.shared.OxmlElement('w:hyperlink')\n",
    "    hyperlink.set(docx.oxml.shared.qn('r:id'), r_id,)\n",
    "\n",
    "    # Create a w:r element\n",
    "    new_run = docx.oxml.shared.OxmlElement('w:r')\n",
    "\n",
    "    # Create a w:rPr element\n",
    "    rPr = docx.oxml.shared.OxmlElement('w:rPr')\n",
    "\n",
    "    # Add color element, default to blue\n",
    "    c = docx.oxml.shared.OxmlElement('w:color')\n",
    "    c.set(docx.oxml.shared.qn('w:val'), '0000FF')\n",
    "    rPr.append(c)\n",
    "\n",
    "    # Add underline element\n",
    "    u = docx.oxml.shared.OxmlElement('w:u')\n",
    "    u.set(docx.oxml.shared.qn('w:val'), 'single')\n",
    "    rPr.append(u)\n",
    "\n",
    "    # Join all the xml elements together and add the text\n",
    "    new_run.append(rPr)\n",
    "    t = docx.oxml.shared.OxmlElement('w:t')\n",
    "    t.text = text\n",
    "    new_run.append(t)\n",
    "    hyperlink.append(new_run)\n",
    "\n",
    "    paragraph._p.append(hyperlink)\n",
    "\n",
    "    return hyperlink\n",
    "\n",
    "def add_formatted_text(paragraph, text):\n",
    "    \"\"\"Parses markdown-style links [title](url) and adds them to paragraph\"\"\"\n",
    "    # Simple regex to find [title](url)\n",
    "    pattern = r'\\[(.*?)\\]\\((.*?)\\)'\n",
    "    last_end = 0\n",
    "    \n",
    "    for match in re.finditer(pattern, text):\n",
    "        # Add plain text before the link\n",
    "        paragraph.add_run(text[last_end:match.start()])\n",
    "        \n",
    "        # Add the hyperlink\n",
    "        link_text = match.group(1)\n",
    "        link_url = match.group(2)\n",
    "        add_hyperlink(paragraph, link_text, link_url)\n",
    "        \n",
    "        last_end = match.end()\n",
    "    \n",
    "    # Add remaining plain text\n",
    "    paragraph.add_run(text[last_end:])\n",
    "\n",
    "# Robust logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Robust Step 2: Extract Marking Scheme to Excel initialized\")\n",
    "print(f\"‚úì Session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Configuration\n",
    "prefix = \"VTC Test\"  # Change this to your exam name\n",
    "dataset = \"sample\"   # Change to your dataset folder\n",
    "\n",
    "# Setup paths with validation\n",
    "try:\n",
    "    paths = setup_paths(prefix, dataset)\n",
    "    marking_scheme_word_file = f\"../{dataset}/{prefix} Marking Scheme.docx\"\n",
    "    marking_scheme_excel_file = paths[\"marking_scheme_file\"]\n",
    "    \n",
    "    # Validate input file exists\n",
    "    if not os.path.exists(marking_scheme_word_file):\n",
    "        raise FileNotFoundError(f\"Marking scheme file not found: {marking_scheme_word_file}\")\n",
    "    \n",
    "    logger.info(f\"‚úì Input file validated: {marking_scheme_word_file}\")\n",
    "    logger.info(f\"‚úì Output file will be: {marking_scheme_excel_file}\")\n",
    "    \n",
    "    print(f\"üìÅ Input: {marking_scheme_word_file}\")\n",
    "    print(f\"üìÅ Output: {marking_scheme_excel_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Setup failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a64616fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,177 - INFO - ‚úì Gemini client initialized successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Vertex AI Express Mode initialized\n",
      "ü§ñ Gemini AI client ready\n"
     ]
    }
   ],
   "source": [
    "# Robust Gemini client initialization with error handling\n",
    "try:\n",
    "    client = init_gemini_client()\n",
    "    logger.info(\"‚úì Gemini client initialized successfully\")\n",
    "    print(\"ü§ñ Gemini AI client ready\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Failed to initialize Gemini client: {e}\")\n",
    "    print(f\"‚ùå Gemini initialization failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d68d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,237 - INFO - Processing Word document: ../sample/VTC Test Marking Scheme.docx\n",
      "2026-01-07 14:19:02,245 - INFO - File size: 18,126 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,520 - INFO - ‚úì Extracted 4,271 characters of markdown content\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Document processed successfully\n",
      "üìÑ Content length: 4,271 characters\n",
      "\n",
      "üìã Document Preview:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Detailed Marking Scheme (0-10 Scale)**\n",
       "\n",
       "Use the following rubric to determine the score for each q.\n",
       "\n",
       "**Q1: The Role of VTC**  \n",
       "The VTC is the largest provider of **VPET** in Hong Kong. Briefly explain what **VPET** stands for and why it is important for Hong Kong‚Äôs workforce development.\n",
       "\n",
       "  * **Answer:** VPET stands for **Vocational and Professional Education and Training**. It is important because it provides students with practical skills and specialized knowledge needed by industries, ensuring Hong Kong has a skilled labor force to support the economy.\n",
       "  * **Marking Breakdown:**\n",
       "    * **[2 marks]** Correctly stating \"Vocational and Professional Education and Training\".\n",
       "    * **[4 marks]** Explaining that it focuses on _practical skills_ or _specialized trades_.\n",
       "    * **[4 marks]** Explaining the benefit to the workforce (reducing skills gap, employment readiness).\n",
       "\n",
       "\n",
       "\n",
       "**Q2: Member Institutions**  \n",
       "Compare **IVE (Hong Kong Institute of Vocational Education)** and **THEi (Technologic..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robust document processing with comprehensive error handling\n",
    "def process_word_document(file_path):\n",
    "    \"\"\"Process Word document with error handling and validation\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Processing Word document: {file_path}\")\n",
    "        \n",
    "        # Validate file exists and is readable\n",
    "        if not os.path.exists(file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        file_size = os.path.getsize(file_path)\n",
    "        logger.info(f\"File size: {file_size:,} bytes\")\n",
    "        \n",
    "        # Convert .docx to HTML using mammoth\n",
    "        with open(file_path, \"rb\") as docx_file:\n",
    "            result = mammoth.convert_to_html(docx_file)\n",
    "            html_content = result.value\n",
    "            \n",
    "            # Check for conversion warnings\n",
    "            if result.messages:\n",
    "                logger.warning(f\"Mammoth conversion warnings: {len(result.messages)}\")\n",
    "                for msg in result.messages[:5]:  # Show first 5 warnings\n",
    "                    logger.warning(f\"  - {msg}\")\n",
    "        \n",
    "        # Convert HTML to markdown using html2text\n",
    "        h = html2text.HTML2Text()\n",
    "        h.ignore_links = False\n",
    "        h.body_width = 0  # Don't wrap text\n",
    "        h.ignore_images = True\n",
    "        h.ignore_tables = False\n",
    "        \n",
    "        markdown_content = h.handle(html_content)\n",
    "        \n",
    "        # Validate content\n",
    "        if not markdown_content.strip():\n",
    "            raise ValueError(\"No content extracted from document\")\n",
    "        \n",
    "        content_length = len(markdown_content)\n",
    "        logger.info(f\"‚úì Extracted {content_length:,} characters of markdown content\")\n",
    "        \n",
    "        return markdown_content, html_content\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Document processing failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Process the document\n",
    "try:\n",
    "    markdown_content, html_content = process_word_document(marking_scheme_word_file)\n",
    "    print(\"‚úÖ Document processed successfully\")\n",
    "    print(f\"üìÑ Content length: {len(markdown_content):,} characters\")\n",
    "    \n",
    "    # Display preview of markdown content\n",
    "    print(\"\\nüìã Document Preview:\")\n",
    "    display(Markdown(markdown_content[:1000] + \"...\" if len(markdown_content) > 1000 else markdown_content))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Document processing failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17f884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,581 - INFO - Marking scheme cache hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Processing document with Gemini AI...\n",
      "‚úÖ AI extraction successful!\n",
      "üìä Extracted 5 questions\n",
      "üìã General grading guide: 491 characters\n"
     ]
    }
   ],
   "source": [
    "# Execute AI extraction using the imported agent\n",
    "try:\n",
    "    print(\"ü§ñ Processing document with Gemini AI...\")\n",
    "    # extract_marking_scheme_with_ai is imported from agents.marking_scheme_agent.agent\n",
    "    questions_data, general_guide = await extract_marking_scheme_with_ai(markdown_content)\n",
    "    \n",
    "    print(f\"‚úÖ AI extraction successful!\")\n",
    "    print(f\"üìä Extracted {len(questions_data)} questions\")\n",
    "    if general_guide:\n",
    "        print(f\"üìã General grading guide: {len(general_guide)} characters\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå AI extraction failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0504e269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,690 - INFO - Validating extracted questions...\n",
      "2026-01-07 14:19:02,697 - INFO - Appending general grading guide to marking schemes\n",
      "2026-01-07 14:19:02,706 - INFO - ‚úì Validation passed: 5 questions, 50 total marks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[32m‚úÖ VALIDATION SUCCESSFUL!\u001b[0m\n",
      "üìä Questions: 5\n",
      "üìä Total marks: 50\n",
      "üìä Average marks per question: 10.0\n",
      "\n",
      "üìã Extracted Questions:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>question_text</th>\n",
       "      <th>marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>The VTC is the largest provider of **VPET** in...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>Compare **IVE (Hong Kong Institute of Vocation...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>VTC emphasizes the **\" Think and Do\"** approac...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>If a Secondary 6 student does **not** achieve ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>Why does the VTC collaborate closely with indu...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_number                                      question_text  marks\n",
       "0              Q1  The VTC is the largest provider of **VPET** in...     10\n",
       "1              Q2  Compare **IVE (Hong Kong Institute of Vocation...     10\n",
       "2              Q3  VTC emphasizes the **\" Think and Do\"** approac...     10\n",
       "3              Q4  If a Secondary 6 student does **not** achieve ...     10\n",
       "4              Q5  Why does the VTC collaborate closely with indu...     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:02,755 - INFO - Starting sequential marking scheme verification...\n",
      "2026-01-07 14:19:02,759 - INFO - AI execution attempt 1/3 for marking_scheme_verifier\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ü§ñ Verifying content with Google Search Grounding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:19:03,283 - INFO - Sending out request, model: gemini-3-flash-preview, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2026-01-07 14:19:03,290 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2026-01-07 14:19:24,581 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-07 14:19:24,588 - INFO - Response received from the model.\n",
      "2026-01-07 14:19:24,772 - INFO - Sending out request, model: gemini-3-flash-preview, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2026-01-07 14:19:24,775 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2026-01-07 14:20:19,374 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-07 14:20:19,384 - INFO - Response received from the model.\n",
      "2026-01-07 14:20:19,389 - INFO - ‚úì Sequential verification completed: 5 items checked\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Verification Complete!\n",
      "üìã General Feedback:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The marking scheme is highly accurate and ready for use. The terminology matches current Hong Kong educational policy (VPET) and VTC‚Äôs institutional structure. No factual errors were found. This evaluation confirms that the marking scheme is factually accurate and aligns with the official standards and terminology of the Vocational Training Council (VTC) in Hong Kong. [vtc.edu.hk](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGfYjWT3BilK0Z-osBdBJkrXPQjTZDsS96PhghiYYnUHdoFpqFUpVSQHZDE4dIKCXYhvEE8x1Z4-BwC-kdHBBBLMTaY8h9bLVoJhUOxj-2i2_Jt848kCldR_bb5ZQ3CyZuT4EUrO9Yj)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_number</th>\n",
       "      <th>is_correct</th>\n",
       "      <th>feedback</th>\n",
       "      <th>suggestion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>True</td>\n",
       "      <td>Terminology is 100% correct. VTC is officially...</td>\n",
       "      <td>The marking scheme is excellent. To make it ev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>True</td>\n",
       "      <td>Correctly distinguishes between the sub-degree...</td>\n",
       "      <td>The answer is correct. You might add that THEi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>True</td>\n",
       "      <td>This is the official VTC motto. The explanatio...</td>\n",
       "      <td>The marking breakdown is well-balanced. Ensure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>True</td>\n",
       "      <td>DFS and DVE are the standard \"bridge\" programm...</td>\n",
       "      <td>The answer is accurate. Note that successful c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>True</td>\n",
       "      <td>Benefits listed (internships, equipment) are c...</td>\n",
       "      <td>The examples provided (internships, equipment)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  question_number  is_correct  \\\n",
       "0              Q1        True   \n",
       "1              Q2        True   \n",
       "2              Q3        True   \n",
       "3              Q4        True   \n",
       "4              Q5        True   \n",
       "\n",
       "                                            feedback  \\\n",
       "0  Terminology is 100% correct. VTC is officially...   \n",
       "1  Correctly distinguishes between the sub-degree...   \n",
       "2  This is the official VTC motto. The explanatio...   \n",
       "3  DFS and DVE are the standard \"bridge\" programm...   \n",
       "4  Benefits listed (internships, equipment) are c...   \n",
       "\n",
       "                                          suggestion  \n",
       "0  The marking scheme is excellent. To make it ev...  \n",
       "1  The answer is correct. You might add that THEi...  \n",
       "2  The marking breakdown is well-balanced. Ensure...  \n",
       "3  The answer is accurate. Note that successful c...  \n",
       "4  The examples provided (internships, equipment)...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Robust validation and data processing\n",
    "def validate_and_process_questions(questions_data, general_guide):\n",
    "    \"\"\"Comprehensive validation and processing of extracted questions\"\"\"\n",
    "    try:\n",
    "        logger.info(\"Validating extracted questions...\")\n",
    "        \n",
    "        # Comprehensive validation\n",
    "        validation_errors = []\n",
    "        warnings = []\n",
    "        \n",
    "        if not questions_data:\n",
    "            validation_errors.append(\"No questions extracted from document\")\n",
    "            \n",
    "        for i, question in enumerate(questions_data):\n",
    "            q_num = question.get('question_number', f'Question {i+1}')\n",
    "            \n",
    "            # Validate required fields\n",
    "            if not question.get('question_text', '').strip():\n",
    "                validation_errors.append(f\"{q_num}: Missing question text\")\n",
    "            \n",
    "            if not question.get('marking_scheme', '').strip():\n",
    "                validation_errors.append(f\"{q_num}: Missing marking scheme\")\n",
    "            \n",
    "            # Validate marks\n",
    "            marks = question.get('marks', 0)\n",
    "            if not isinstance(marks, int) or marks <= 0:\n",
    "                validation_errors.append(f\"{q_num}: Invalid marks value ({marks})\")\n",
    "            elif marks > 50:\n",
    "                warnings.append(f\"{q_num}: High marks value ({marks}) - please verify\")\n",
    "        \n",
    "        # Report validation results\n",
    "        if validation_errors:\n",
    "            print(\"\\n\" + \"=\"*60)\n",
    "            print(colored(\"‚ùå VALIDATION ERRORS DETECTED!\", \"red\", attrs=['bold']))\n",
    "            print(\"=\"*60)\n",
    "            for error in validation_errors:\n",
    "                print(colored(f\"  ‚Ä¢ {error}\", \"red\"))\n",
    "            print(\"=\"*60)\n",
    "            raise ValueError(f\"Validation failed: {len(validation_errors)} error(s) found\")\n",
    "        \n",
    "        if warnings:\n",
    "            print(\"\\n\" + \"‚ö†Ô∏è  VALIDATION WARNINGS:\")\n",
    "            for warning in warnings:\n",
    "                print(colored(f\"  ‚Ä¢ {warning}\", \"yellow\"))\n",
    "            print()\n",
    "        \n",
    "        # Process questions - append general guide if available\n",
    "        if general_guide and general_guide.strip():\n",
    "            logger.info(\"Appending general grading guide to marking schemes\")\n",
    "            for question in questions_data:\n",
    "                question['marking_scheme'] = f\"{question['marking_scheme']}\\n\\n---\\n\\n**General Grading Guide:**\\n{general_guide}\"\n",
    "        \n",
    "        # Create DataFrame with formatting\n",
    "        df = pd.DataFrame(questions_data)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        total_questions = len(questions_data)\n",
    "        total_marks = df['marks'].sum()\n",
    "        avg_marks = df['marks'].mean()\n",
    "        \n",
    "        logger.info(f\"‚úì Validation passed: {total_questions} questions, {total_marks} total marks\")\n",
    "        \n",
    "        print(colored(\"‚úÖ VALIDATION SUCCESSFUL!\", \"green\", attrs=['bold']))\n",
    "        print(f\"üìä Questions: {total_questions}\")\n",
    "        print(f\"üìä Total marks: {total_marks}\")\n",
    "        print(f\"üìä Average marks per question: {avg_marks:.1f}\")\n",
    "        \n",
    "        return df, total_questions, total_marks\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Validation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Execute validation and processing\n",
    "try:\n",
    "    df, total_questions, total_marks = validate_and_process_questions(questions_data, general_guide)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\\nüìã Extracted Questions:\")\n",
    "    display(df[['question_number', 'question_text', 'marks']].head(10))\n",
    "    \n",
    "    if len(df) > 10:\n",
    "        print(f\"... and {len(df) - 10} more questions\")\n",
    "    \n",
    "    # --- NEW VERIFICATION STEP ---\n",
    "    print(\"\\nü§ñ Verifying content with Google Search Grounding...\")\n",
    "    verification_items, verification_general_feedback = await verify_marking_scheme_with_ai(questions_data)\n",
    "    \n",
    "    # Display Verification Results\n",
    "    print(f\"\\n‚úÖ Verification Complete!\")\n",
    "    if verification_general_feedback:\n",
    "        print(\"üìã General Feedback:\")\n",
    "        display(Markdown(verification_general_feedback))\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    if verification_items:\n",
    "        v_df = pd.DataFrame(verification_items)\n",
    "        display(v_df[['question_number', 'is_correct', 'feedback', 'suggestion']])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No verification items returned.\")\n",
    "        v_df = pd.DataFrame() # Empty DataFrame\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Validation failed: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65aa866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-07 14:20:19,481 - INFO - Creating Excel report: ../sample/VTC Test Marking Scheme.xlsx\n",
      "2026-01-07 14:20:19,489 - INFO - ‚úì Created backup: ../sample/VTC Test Marking Scheme.xlsx.backup.20260107_142019\n",
      "2026-01-07 14:20:19,798 - INFO - ‚úì Created 'Marking Scheme' sheet\n",
      "2026-01-07 14:20:19,804 - INFO - ‚úì Created 'Summary' sheet\n",
      "2026-01-07 14:20:19,808 - INFO - ‚úì Created 'Question Overview' sheet\n",
      "2026-01-07 14:20:19,813 - INFO - ‚úì Created 'Validation' sheet\n",
      "2026-01-07 14:20:19,816 - INFO - ‚úì Created 'Content Verification' sheet\n",
      "2026-01-07 14:20:19,862 - INFO - ‚úì Excel file created successfully (12,401 bytes)\n",
      "2026-01-07 14:20:19,866 - INFO - Creating Word verification report: ../sample/VTC Test Marking Scheme_verification.docx\n",
      "2026-01-07 14:20:19,981 - INFO - ‚úì Word report created successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Verification Word report: ../sample/VTC Test Marking Scheme_verification.docx\n",
      "\n",
      "============================================================\n",
      "\u001b[1m\u001b[32müéâ STEP 2 COMPLETED SUCCESSFULLY!\u001b[0m\n",
      "============================================================\n",
      "üìÅ Output file: ../sample/VTC Test Marking Scheme.xlsx\n",
      "üìä Questions processed: 5\n",
      "üìä Total marks: 50\n",
      "üìã Sheets created: Marking Scheme, Summary, Question Overview, Validation, Content Verification\n",
      "‚è∞ Processing completed at: 2026-01-07 14:20:19\n",
      "============================================================\n",
      "\n",
      "‚úÖ Ready for Step 3: Question Annotations\n"
     ]
    }
   ],
   "source": [
    "# Robust Excel export with comprehensive formatting and backup\n",
    "def create_excel_report(df, marking_scheme_excel_file, total_questions, total_marks, verification_df=None, verification_feedback=\"\"):\n",
    "    \"\"\"Create comprehensive Excel report with multiple sheets and formatting\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Creating Excel report: {marking_scheme_excel_file}\")\n",
    "        \n",
    "        # Create backup of existing file if it exists\n",
    "        if os.path.exists(marking_scheme_excel_file):\n",
    "            backup_file = f\"{marking_scheme_excel_file}.backup.{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "            shutil.copy2(marking_scheme_excel_file, backup_file)\n",
    "            logger.info(f\"‚úì Created backup: {backup_file}\")\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(marking_scheme_excel_file), exist_ok=True)\n",
    "        \n",
    "        # Create Excel writer with multiple sheets\n",
    "        with pd.ExcelWriter(marking_scheme_excel_file, engine='openpyxl') as writer:\n",
    "            # Sheet 1: Marking Scheme (detailed rubric)\n",
    "            df.to_excel(writer, sheet_name='Marking Scheme', index=False)\n",
    "            logger.info(\"‚úì Created 'Marking Scheme' sheet\")\n",
    "            \n",
    "            # Sheet 2: Summary with statistics\n",
    "            summary_data = {\n",
    "                'Metric': [\n",
    "                    'Total Questions',\n",
    "                    'Total Marks',\n",
    "                    'Average Marks per Question',\n",
    "                    'Min Marks per Question',\n",
    "                    'Max Marks per Question',\n",
    "                    'Verification Feedback',\n",
    "                    'Generated On',\n",
    "                    'Input File',\n",
    "                    'Output File'\n",
    "                ],\n",
    "                'Value': [\n",
    "                    total_questions,\n",
    "                    total_marks,\n",
    "                    f\"{df['marks'].mean():.1f}\",\n",
    "                    df['marks'].min(),\n",
    "                    df['marks'].max(),\n",
    "                    verification_feedback,\n",
    "                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    os.path.basename(marking_scheme_word_file),\n",
    "                    os.path.basename(marking_scheme_excel_file)\n",
    "                ]\n",
    "            }\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            logger.info(\"‚úì Created 'Summary' sheet\")\n",
    "            \n",
    "            # Sheet 3: Question Overview (simplified view)\n",
    "            overview_df = df[['question_number', 'question_text', 'marks']].copy()\n",
    "            overview_df.to_excel(writer, sheet_name='Question Overview', index=False)\n",
    "            logger.info(\"‚úì Created 'Question Overview' sheet\")\n",
    "            \n",
    "            # Sheet 4: Validation Report\n",
    "            validation_data = {\n",
    "                'Check': [\n",
    "                    'All questions have marking schemes',\n",
    "                    'All questions have valid marks',\n",
    "                    'Question numbers are unique',\n",
    "                    'Total marks calculated',\n",
    "                    'General grading guide processed'\n",
    "                ],\n",
    "                'Status': [\n",
    "                    '‚úÖ PASS' if all(q.get('marking_scheme', '').strip() for q in questions_data) else '‚ùå FAIL',\n",
    "                    '‚úÖ PASS' if all(isinstance(q.get('marks', 0), int) and q.get('marks', 0) > 0 for q in questions_data) else '‚ùå FAIL',\n",
    "                    '‚úÖ PASS' if len(set(q.get('question_number', '') for q in questions_data)) == len(questions_data) else '‚ö†Ô∏è WARNING',\n",
    "                    f'‚úÖ PASS ({total_marks} marks)',\n",
    "                    '‚úÖ PROCESSED' if general_guide else '‚ÑπÔ∏è NOT FOUND'\n",
    "                ]\n",
    "            }\n",
    "            validation_df = pd.DataFrame(validation_data)\n",
    "            validation_df.to_excel(writer, sheet_name='Validation', index=False)\n",
    "            logger.info(\"‚úì Created 'Validation' sheet\")\n",
    "            \n",
    "            # Sheet 5: Content Verification (Grounding)\n",
    "            if verification_df is not None and not verification_df.empty:\n",
    "                verification_df.to_excel(writer, sheet_name='Content Verification', index=False)\n",
    "                logger.info(\"‚úì Created 'Content Verification' sheet\")\n",
    "        \n",
    "        # Verify file was created successfully\n",
    "        if os.path.exists(marking_scheme_excel_file):\n",
    "            file_size = os.path.getsize(marking_scheme_excel_file)\n",
    "            logger.info(f\"‚úì Excel file created successfully ({file_size:,} bytes)\")\n",
    "            return True\n",
    "        else:\n",
    "            raise FileNotFoundError(\"Excel file was not created\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Excel export failed: {e}\")\n",
    "        raise\n",
    "\n",
    "def create_verification_word_report(verification_df, verification_feedback, output_path):\n",
    "    \"\"\"Create a Word report for the verification results\"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Creating Word verification report: {output_path}\")\n",
    "        doc = Document()\n",
    "        doc.add_heading('Marking Scheme Verification Report', 0)\n",
    "        \n",
    "        # General Feedback\n",
    "        doc.add_heading('General Feedback', level=1)\n",
    "        if verification_feedback:\n",
    "            p = doc.add_paragraph()\n",
    "            add_formatted_text(p, verification_feedback)\n",
    "        else:\n",
    "            doc.add_paragraph(\"No general feedback available.\")\n",
    "            \n",
    "        # Question Feedback\n",
    "        doc.add_heading('Question Verification', level=1)\n",
    "        \n",
    "        if verification_df is not None and not verification_df.empty:\n",
    "            for _, row in verification_df.iterrows():\n",
    "                q_num = row.get('question_number', 'Unknown Question')\n",
    "                is_correct = row.get('is_correct', False)\n",
    "                feedback = row.get('feedback', '')\n",
    "                suggestion = row.get('suggestion', '')\n",
    "                \n",
    "                heading = doc.add_heading(f\"{q_num}\", level=2)\n",
    "                \n",
    "                # Status\n",
    "                p = doc.add_paragraph()\n",
    "                run = p.add_run(f\"Status: {'‚úÖ Correct' if is_correct else '‚ùå Incorrect'}\")\n",
    "                run.bold = True\n",
    "                if not is_correct:\n",
    "                    run.font.color.rgb = RGBColor(255, 0, 0)\n",
    "\n",
    "                # Feedback\n",
    "                doc.add_heading('Feedback:', level=3)\n",
    "                p = doc.add_paragraph()\n",
    "                add_formatted_text(p, feedback)\n",
    "                \n",
    "                # Suggestion\n",
    "                if suggestion and suggestion != 'None':\n",
    "                    doc.add_heading('Suggestion:', level=3)\n",
    "                    p = doc.add_paragraph()\n",
    "                    add_formatted_text(p, suggestion)\n",
    "                \n",
    "                doc.add_paragraph(\"_\" * 40) # Separator\n",
    "        else:\n",
    "            doc.add_paragraph(\"No question-level verification data available.\")\n",
    "            \n",
    "        doc.save(output_path)\n",
    "        logger.info(f\"‚úì Word report created successfully\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Word report creation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Execute Excel export\n",
    "try:\n",
    "    # Check if v_df exists (from previous cell)\n",
    "    if 'v_df' not in locals():\n",
    "        v_df = None\n",
    "    if 'verification_general_feedback' not in locals():\n",
    "        verification_general_feedback = \"\"\n",
    "        \n",
    "    success = create_excel_report(df, marking_scheme_excel_file, total_questions, total_marks, v_df, verification_general_feedback)\n",
    "    \n",
    "    if success:\n",
    "        # Also create Word report for verification\n",
    "        if v_df is not None or verification_general_feedback:\n",
    "            word_report_file = marking_scheme_excel_file.replace('.xlsx', '_verification.docx')\n",
    "            create_verification_word_report(v_df, verification_general_feedback, word_report_file)\n",
    "            print(f\"üìÅ Verification Word report: {word_report_file}\")\n",
    "\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(colored(\"üéâ STEP 2 COMPLETED SUCCESSFULLY!\", \"green\", attrs=['bold']))\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìÅ Output file: {marking_scheme_excel_file}\")\n",
    "        print(f\"üìä Questions processed: {total_questions}\")\n",
    "        print(f\"üìä Total marks: {total_marks}\")\n",
    "        print(f\"üìã Sheets created: Marking Scheme, Summary, Question Overview, Validation, Content Verification\")\n",
    "        print(f\"‚è∞ Processing completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(\"=\"*60)\n",
    "        print(\"\\n‚úÖ Ready for Step 3: Question Annotations\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Excel export failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba75e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
