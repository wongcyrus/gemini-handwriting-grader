{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Answer Bounding Boxes\n",
    "1. Convert the exam PDF into page images.\n",
    "2. Auto-detect bounding boxes with AI.\n",
    "3. Manually review and adjust each answer region.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Comprehensive validation of input files and setup\n",
    "- ‚úÖ Robust OCR processing with retry logic and caching\n",
    "- ‚úÖ Progress tracking for multi-page processing\n",
    "- ‚úÖ Coordinate validation and scaling\n",
    "- ‚úÖ Robust error handling and recovery\n",
    "- ‚úÖ Detailed processing reports and validation summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command extracts cache for the sample to speed up and reduce costs for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b' 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/143.0.0.0 Sa']\n",
      "Bad pipe message: %s [b'ri/537.36\\r\\nAccept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/', b'ng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\\r\\nAccept-Encoding: gzip, deflate, br, zstd\\r\\nA']\n",
      "Bad pipe message: %s [b'ept-Language: en-US,en;q=0.9,zh-TW;q=0.8,zh;q=0.7\\r\\nPriority: u=0, i\\r\\nReferer: https://studio.fireb', b'e.google.com/\\r\\nSec-Ch-Ua: \"Google Chrome\";v=\"143\", \"Chromium\";v=\"143\", \"Not A(Brand\";v=\"24\"\\r\\nSec', b'h-Ua-Arch: \"x86\"\\r\\nSec-Ch-Ua-Bitness: \"64\"\\r\\nS', b'-Ch-Ua-Form-Factors: \"Desktop\"\\r\\nSec-Ch-Ua-Full-Version: \"143.0.7499.170\"\\r\\nSec-Ch-Ua-Full-Version-Lis', b' \"Google Chrome\";v=\"143.0.7499.170\", \"Chromium\";v=\"143.0.7499.170\", \"Not A(Brand\";v=\"24.0.0.0\"\\r\\nSec-Ch-Ua-Mobile: ?']\n",
      "Bad pipe message: %s [b'\\nSec-Ch-Ua-Model: \"\"\\r\\nSec-Ch-Ua-Platform: \"Wind', b's\"\\r\\nSec-Ch-Ua-Platform-Version: \"19.0.0\"\\r\\nSec-Ch-Ua-Wow64: ?0\\r\\nSec-Fetch-Dest: iframe\\r\\nSec-Fetch-Mode: navigat', b'\\nSec-Fetch-Site: cross-site\\r\\nSec-Fetch-Storage-Access: active\\r\\nSec-Fetch-User: ?1\\r\\nSec-User-Ip: 10.2', b'20.195\\r\\nUpgrade-Insecure-Requests: 1\\r\\nX-Forward']\n",
      "Bad pipe message: %s [b'-Host: 38747-firebase-gemini-ai-grader-1767589248216.cluster-ejd22kqny5htuv5dfowoyipt52.cloudworksta']\n",
      "2026-01-09 07:28:46,779 - INFO - Mapped GOOGLE_GENAI_API_KEY to GOOGLE_API_KEY for ADK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup validation passed\n"
     ]
    }
   ],
   "source": [
    "from grading_utils import (\n",
    "    setup_paths, create_directories, init_gemini_client, \n",
    "    validate_required_files, print_validation_summary\n",
    ")\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from agents.annotation_agent.agent import extract_annotations_with_ai\n",
    "from typing import List\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "prefix = \"VTC Test\"\n",
    "paths = setup_paths(prefix, \"sample\")\n",
    "# Configuration - can be adjusted for testing\n",
    "number_of_pages = 2  # Set to specific number for testing, or use len(pages) after conversion\n",
    "\n",
    "# Validate required files exist\n",
    "missing_files = validate_required_files(paths)\n",
    "if missing_files:\n",
    "    print(\"‚ùå Setup validation failed!\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  Missing: {file}\")\n",
    "    raise FileNotFoundError(\"Please ensure all required files are present.\")\n",
    "\n",
    "pdf_file = paths[\"pdf_file\"]\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Setup validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:28:46,825 - INFO - ‚úì Created all necessary directories\n",
      "2026-01-09 07:28:46,827 - INFO - Converting PDF to images...\n",
      "2026-01-09 07:28:46,827 - INFO - Converting PDF to images...\n",
      "2026-01-09 07:28:49,546 - INFO - ‚úì Converted PDF to 8 images in 2.72s\n",
      "Saving images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 17.86it/s]\n",
      "2026-01-09 07:28:50,000 - INFO - ‚úì Saved 8 images to ../marking_form/VTC Test/images/\n"
     ]
    }
   ],
   "source": [
    "# Robust directory creation and PDF conversion\n",
    "try:\n",
    "    # Extract paths from setup\n",
    "    file_name = paths[\"file_name\"]\n",
    "    base_path = paths[\"base_path\"]\n",
    "    base_path_images = paths[\"base_path_images\"]\n",
    "    base_path_annotations = paths[\"base_path_annotations\"]\n",
    "\n",
    "    # Create directories with error handling\n",
    "    create_directories(paths)\n",
    "    logger.info(\"‚úì Created all necessary directories\")\n",
    "\n",
    "    # Convert PDF to images with progress tracking\n",
    "    logger.info(\"Converting PDF to images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pages = convert_from_path(pdf_file, fmt='jpeg')\n",
    "    conversion_time = time.time() - start_time\n",
    "    \n",
    "    logger.info(f\"‚úì Converted PDF to {len(pages)} images in {conversion_time:.2f}s\")\n",
    "    \n",
    "    # Save images with progress tracking\n",
    "    for count, page in enumerate(tqdm(pages, desc=\"Saving images\")):\n",
    "        image_path = f'{base_path_images}{count}.jpg'\n",
    "        page.save(image_path, 'JPEG')\n",
    "    \n",
    "    logger.info(f\"‚úì Saved {len(pages)} images to {base_path_images}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to convert PDF or create directories: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "# Robust utility functions with error handling\n",
    "def update_json_file(annotations, path):\n",
    "    \"\"\"Update JSON file with error handling.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(annotations, f, indent=4)\n",
    "        logger.info(f\"‚úì Updated annotations file: {path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to update JSON file {path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def image_to_data_url(filename):\n",
    "    \"\"\"Convert image to data URL with error handling.\"\"\"\n",
    "    try:\n",
    "        ext = filename.split(\".\")[-1].lower()\n",
    "        if ext == 'jpg':\n",
    "            ext = 'jpeg'\n",
    "        prefix = f\"data:image/{ext};base64,\"\n",
    "        \n",
    "        with open(filename, \"rb\") as f:\n",
    "            img = f.read()\n",
    "        return prefix + base64.b64encode(img).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert image to data URL {filename}: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úì Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:28:50,037 - INFO - üîç Using agent-managed prompt for extraction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Starting bounding box extraction...\n",
      "Processing 2 pages with OCR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing pages:   0%|          | 0/2 [00:00<?, ?it/s]2026-01-09 07:28:50,044 - INFO - AI execution attempt 1/3 for annotation_extractor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing page 0 (../marking_form/VTC Test/images/0.jpg)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:28:50,351 - INFO - Sending out request, model: gemini-3-flash-preview, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2026-01-09 07:28:50,353 - INFO - AFC is enabled with max remote calls: 10.\n",
      "2026-01-09 07:29:08,277 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-09 07:29:08,283 - INFO - Response received from the model.\n",
      "2026-01-09 07:29:08,286 - INFO - ‚úì Successfully extracted 6 boxes via ADK output state!\n",
      "Processing pages:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:18<00:18, 18.25s/it]2026-01-09 07:29:08,292 - INFO - AI execution attempt 1/3 for annotation_extractor\n",
      "2026-01-09 07:29:08,470 - INFO - Sending out request, model: gemini-3-flash-preview, backend: GoogleLLMVariant.VERTEX_AI, stream: False\n",
      "2026-01-09 07:29:08,473 - INFO - AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Page 0: Found 6 bounding boxes\n",
      "[\n",
      "  {\n",
      "    \"x\": 134,\n",
      "    \"y\": 205,\n",
      "    \"width\": 134,\n",
      "    \"height\": 17,\n",
      "    \"label\": \"NAME\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 583,\n",
      "    \"y\": 205,\n",
      "    \"width\": 241,\n",
      "    \"height\": 17,\n",
      "    \"label\": \"ID\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 134,\n",
      "    \"y\": 233,\n",
      "    \"width\": 84,\n",
      "    \"height\": 17,\n",
      "    \"label\": \"CLASS\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 134,\n",
      "    \"y\": 260,\n",
      "    \"width\": 719,\n",
      "    \"height\": 110,\n",
      "    \"label\": \"Q1\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 134,\n",
      "    \"y\": 370,\n",
      "    \"width\": 719,\n",
      "    \"height\": 124,\n",
      "    \"label\": \"Q2\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 134,\n",
      "    \"y\": 494,\n",
      "    \"width\": 719,\n",
      "    \"height\": 109,\n",
      "    \"label\": \"Q3\"\n",
      "  }\n",
      "]\n",
      "\n",
      "============================================================\n",
      "Processing page 1 (../marking_form/VTC Test/images/1.jpg)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:29:34,686 - INFO - HTTP Request: POST https://aiplatform.googleapis.com/v1beta1/publishers/google/models/gemini-3-flash-preview:generateContent \"HTTP/1.1 200 OK\"\n",
      "2026-01-09 07:29:34,692 - INFO - Response received from the model.\n",
      "2026-01-09 07:29:34,695 - INFO - ‚úì Successfully extracted 5 boxes via ADK output state!\n",
      "Processing pages: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:44<00:00, 22.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Page 1: Found 5 bounding boxes\n",
      "[\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 178,\n",
      "    \"width\": 132,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"NAME\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 584,\n",
      "    \"y\": 178,\n",
      "    \"width\": 240,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"ID\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 206,\n",
      "    \"width\": 80,\n",
      "    \"height\": 20,\n",
      "    \"label\": \"CLASS\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 234,\n",
      "    \"width\": 719,\n",
      "    \"height\": 111,\n",
      "    \"label\": \"Q4\"\n",
      "  },\n",
      "  {\n",
      "    \"x\": 135,\n",
      "    \"y\": 345,\n",
      "    \"width\": 719,\n",
      "    \"height\": 124,\n",
      "    \"label\": \"Q5\"\n",
      "  }\n",
      "]\n",
      "Removed 3 NAME/ID/CLASS boxes from page 1\n",
      "\n",
      "============================================================\n",
      "‚úÖ BOUNDING BOX EXTRACTION COMPLETED!\n",
      "============================================================\n",
      "üìä Processing Statistics:\n",
      "   Total pages: 2\n",
      "   Successful: 2\n",
      "   Failed: 0\n",
      "   Total boxes found: 8\n",
      "   Processing time: 44.66s\n",
      "   Average per page: 22.33s\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The extraction prompt is now encapsulated within the annotation_agent\n",
    "logger.info(\"üîç Using agent-managed prompt for extraction\")\n",
    "\n",
    "print(\"üîç Starting bounding box extraction...\")\n",
    "print(f\"Processing {number_of_pages} pages with OCR\")\n",
    "\n",
    "aiAnnotation = {}\n",
    "processing_stats = {\n",
    "    'total_pages': number_of_pages,\n",
    "    'successful_pages': 0,\n",
    "    'failed_pages': 0,\n",
    "    'total_boxes': 0,\n",
    "    'processing_time': 0\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each page with progress tracking\n",
    "for i in tqdm(range(number_of_pages), desc=\"Processing pages\"):\n",
    "    image_path = base_path_images + f\"{i}.jpg\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing page {i} ({image_path})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Validate image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Use OCR with retry logic\n",
    "        result = await extract_annotations_with_ai(image_path)\n",
    "        \n",
    "        # Convert Pydantic model to dict and extract boxes\n",
    "        boxes_dict = [box.model_dump() for box in result.boxes]\n",
    "        aiAnnotation[str(i)] = boxes_dict\n",
    "        \n",
    "        processing_stats['successful_pages'] += 1\n",
    "        processing_stats['total_boxes'] += len(boxes_dict)\n",
    "        \n",
    "        print(f\"‚úì Page {i}: Found {len(boxes_dict)} bounding boxes\")\n",
    "        if boxes_dict:\n",
    "            print(json.dumps(boxes_dict, indent=2))\n",
    "        \n",
    "        # Validate bounding boxes\n",
    "        for box in boxes_dict:\n",
    "            if box['width'] <= 0 or box['height'] <= 0:\n",
    "                logger.warning(f\"Invalid box dimensions on page {i}: {box}\")\n",
    "        if i != 0:\n",
    "            filtered_boxes = [b for b in boxes_dict if b['label'] not in {'NAME', 'ID', 'CLASS'}]\n",
    "            removed = len(boxes_dict) - len(filtered_boxes)\n",
    "            if removed:\n",
    "                print(f\"Removed {removed} NAME/ID/CLASS boxes from page {i}\")\n",
    "            boxes_dict = filtered_boxes\n",
    "            aiAnnotation[str(i)] = boxes_dict\n",
    "            processing_stats['total_boxes'] -= removed\n",
    "        if not boxes_dict:\n",
    "            print(\"  (No bounding boxes detected)\")\n",
    "            logger.warning(f\"No bounding boxes found on page {i}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process page {i}: {type(e).__name__}: {e}\")\n",
    "        aiAnnotation[str(i)] = []\n",
    "        processing_stats['failed_pages'] += 1\n",
    "\n",
    "processing_stats['processing_time'] = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ BOUNDING BOX EXTRACTION COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìä Processing Statistics:\")\n",
    "print(f\"   Total pages: {processing_stats['total_pages']}\")\n",
    "print(f\"   Successful: {processing_stats['successful_pages']}\")\n",
    "print(f\"   Failed: {processing_stats['failed_pages']}\")\n",
    "print(f\"   Total boxes found: {processing_stats['total_boxes']}\")\n",
    "print(f\"   Processing time: {processing_stats['processing_time']:.2f}s\")\n",
    "print(f\"   Average per page: {processing_stats['processing_time']/number_of_pages:.2f}s\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "backup = copy.deepcopy(aiAnnotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:29:34,736 - INFO - ‚úì Image dimensions: 1654x2338\n",
      "2026-01-09 07:29:34,738 - INFO - Scaling factors: x=1.654, y=2.338\n",
      "2026-01-09 07:29:34,741 - INFO - ‚úì Saved AI annotations to: ../marking_form/VTC Test/annotations/ai_annotations.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: Width: 1654, Height: 2338\n",
      "\n",
      "üìê Coordinate Scaling Results:\n",
      "   Successfully scaled: 8 boxes\n",
      "   Invalid after scaling: 0 boxes\n",
      "‚úì AI annotations saved to: ../marking_form/VTC Test/annotations/ai_annotations.json\n"
     ]
    }
   ],
   "source": [
    "# Robust coordinate scaling and validation\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "# Get image dimensions for scaling\n",
    "sample_image_path = base_path_images + \"0.jpg\"\n",
    "try:\n",
    "    # Ensure backup exists (in case bounding box cell wasn't run or failed)\n",
    "    if 'backup' not in locals():\n",
    "        logger.warning(\"‚ö†Ô∏è Backup not found - loading AI annotations directly\")\n",
    "        ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "        if os.path.exists(ai_annotations_path):\n",
    "            with open(ai_annotations_path, \"r\") as f:\n",
    "                backup = json.load(f)\n",
    "            logger.info(\"‚úì Loaded backup from saved AI annotations\")\n",
    "        else:\n",
    "            logger.error(\"‚ùå No backup found and no saved annotations available\")\n",
    "            raise FileNotFoundError(\"AI annotations not found. Please run the bounding box extraction cell first.\")\n",
    "    \n",
    "    with Image.open(sample_image_path) as img:\n",
    "        width, height = img.size\n",
    "    \n",
    "    logger.info(f\"‚úì Image dimensions: {width}x{height}\")\n",
    "    print(f\"Image dimensions: Width: {width}, Height: {height}\")\n",
    "    \n",
    "    # Calculate scaling factors\n",
    "    x_scale = width / 1000.0\n",
    "    y_scale = height / 1000.0\n",
    "    \n",
    "    logger.info(f\"Scaling factors: x={x_scale:.3f}, y={y_scale:.3f}\")\n",
    "    \n",
    "    # Apply scaling with validation\n",
    "    aiAnnotation = copy.deepcopy(backup)\n",
    "    scaling_stats = {'scaled_boxes': 0, 'invalid_boxes': 0}\n",
    "    \n",
    "    for i in range(number_of_pages):\n",
    "        for item in aiAnnotation[str(i)]:\n",
    "            # Store original values for validation\n",
    "            orig_x, orig_y = item['x'], item['y']\n",
    "            orig_w, orig_h = item['width'], item['height']\n",
    "            \n",
    "            # Apply scaling\n",
    "            item['x'] = int(round(item['x'] * x_scale))\n",
    "            item['y'] = int(round(item['y'] * y_scale))\n",
    "            item['width'] = int(round(item['width'] * x_scale))\n",
    "            item['height'] = int(round(item['height'] * y_scale))\n",
    "            \n",
    "            # Validate scaled coordinates\n",
    "            if (item['x'] < 0 or item['y'] < 0 or \n",
    "                item['x'] + item['width'] > width or \n",
    "                item['y'] + item['height'] > height):\n",
    "                logger.warning(f\"Scaled box out of bounds on page {i}: {item}\")\n",
    "                scaling_stats['invalid_boxes'] += 1\n",
    "            else:\n",
    "                scaling_stats['scaled_boxes'] += 1\n",
    "    \n",
    "    print(f\"\\nüìê Coordinate Scaling Results:\")\n",
    "    print(f\"   Successfully scaled: {scaling_stats['scaled_boxes']} boxes\")\n",
    "    print(f\"   Invalid after scaling: {scaling_stats['invalid_boxes']} boxes\")\n",
    "    \n",
    "    # Save AI annotations\n",
    "    ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "    \n",
    "    with open(ai_annotations_path, \"w\") as f:\n",
    "        json.dump(aiAnnotation, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"‚úì Saved AI annotations to: {ai_annotations_path}\")\n",
    "    print(f\"‚úì AI annotations saved to: {ai_annotations_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process image dimensions or scaling: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Annotation Review and Adjustment\n",
    "\n",
    "Please ensure the following are clearly marked on each page before grading:\n",
    "- **ID**: Student identification number\n",
    "- **NAME**: Student name field\n",
    "- **CLASS**: Student class/section\n",
    "\n",
    "Use the interactive widget below to review and adjust the AI-generated bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-09 07:29:35,111 - INFO - Found 8 image files for annotation\n",
      "2026-01-09 07:29:35,115 - INFO - ‚úì Loaded AI annotations for 2 pages\n",
      "2026-01-09 07:29:35,135 - INFO - ‚úì Merged manual annotations for 2 pages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Loaded AI annotations for 2 pages\n",
      "‚úì Merged manual annotations for 2 pages\n",
      "Total pages with annotations: ['0', '1']\n",
      "\n",
      "üéØ Interactive annotation widget ready!\n",
      "Use the widget below to review and adjust bounding boxes.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a95984d42854808b0c76b65acedb6e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>üìù Robust Interactive Annotation Tool</h3>'), HTML(value='<b>Status:</b> Loaded ‚Ä¶"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Robust interactive annotation widget with comprehensive features\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import ipywidgets as widgets\n",
    "import glob\n",
    "\n",
    "# Initialize widget state\n",
    "page = 1\n",
    "pageAndBoundingBoxes = {}\n",
    "\n",
    "# Get all image files\n",
    "files = sorted(glob.glob(base_path_images + \"*.jpg\"))\n",
    "logger.info(f\"Found {len(files)} image files for annotation\")\n",
    "\n",
    "# Create progress widget\n",
    "w_progress = widgets.IntProgress(\n",
    "    value=0, \n",
    "    max=len(files), \n",
    "    description=\"Progress\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# File paths\n",
    "annotations_path = base_path_annotations + \"annotations.json\"\n",
    "ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "\n",
    "# Load existing annotations with priority: manual > AI\n",
    "annotations = {}\n",
    "\n",
    "# Load AI annotations first (as base)\n",
    "if os.path.exists(ai_annotations_path):\n",
    "    try:\n",
    "        with open(ai_annotations_path, \"r\") as f: \n",
    "            annotations = json.load(f)\n",
    "        logger.info(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "        print(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load AI annotations: {e}\")\n",
    "\n",
    "# Then merge/override with manual annotations if they exist\n",
    "if os.path.exists(annotations_path):\n",
    "    try:\n",
    "        with open(annotations_path, \"r\") as f: \n",
    "            manual_annotations = json.load(f)\n",
    "            annotations.update(manual_annotations)  # Manual annotations take priority\n",
    "        logger.info(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "        print(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load manual annotations: {e}\")\n",
    "\n",
    "print(f\"Total pages with annotations: {list(annotations.keys())}\")\n",
    "\n",
    "# Create question input widget\n",
    "question_widget = widgets.Text(\n",
    "    value=\"\", \n",
    "    placeholder=\"Enter question label (e.g., '1', '2', 'NAME', 'ID')\", \n",
    "    description=\"Question:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create status widget\n",
    "status_widget = widgets.HTML(\n",
    "    value=\"<b>Status:</b> Ready to annotate\",\n",
    "    description=\"\"\n",
    ")\n",
    "\n",
    "# Create bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image=image_to_data_url(files[0]) if files else None\n",
    ")\n",
    "w_bbox.attach(question_widget, name=\"label\")\n",
    "\n",
    "# Load initial bounding boxes\n",
    "initial_page = str(w_progress.value)\n",
    "if initial_page in annotations:\n",
    "    w_bbox.bboxes = annotations[initial_page]\n",
    "    status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[initial_page])} boxes for page {w_progress.value}\"\n",
    "else:\n",
    "    w_bbox.bboxes = []\n",
    "    status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "\n",
    "# Robust skip function\n",
    "def on_skip():\n",
    "    if w_progress.value + 1 >= len(files):\n",
    "        status_widget.value = f\"<b>Status:</b> Already at the last page ({len(files)-1})\"\n",
    "        logger.info(f\"Already at the last page ({len(files)-1})\")\n",
    "        return\n",
    "    \n",
    "    w_progress.value += 1\n",
    "    current_page = str(w_progress.value)\n",
    "    \n",
    "    try:\n",
    "        # Load new image in the widget\n",
    "        image_file = files[w_progress.value]\n",
    "        w_bbox.image = image_to_data_url(image_file)\n",
    "        \n",
    "        # Load bounding boxes for current page\n",
    "        if current_page in annotations:\n",
    "            w_bbox.bboxes = annotations[current_page]\n",
    "            status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[current_page])} boxes for page {w_progress.value}\"\n",
    "            logger.info(f\"‚úì Loaded {len(annotations[current_page])} bounding boxes for page {w_progress.value}\")\n",
    "        else:\n",
    "            w_bbox.bboxes = []\n",
    "            status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "            logger.warning(f\"‚ö†Ô∏è No annotations found for page {w_progress.value}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error loading page {w_progress.value}: {e}\"\n",
    "        logger.error(f\"Error loading page {w_progress.value}: {e}\")\n",
    "\n",
    "w_bbox.on_skip(on_skip)\n",
    "\n",
    "# Robust submit function\n",
    "def on_submit():\n",
    "    try:\n",
    "        current_page = str(w_progress.value)\n",
    "        \n",
    "        # Save annotations for current image\n",
    "        annotations[current_page] = w_bbox.bboxes\n",
    "        update_json_file(annotations, annotations_path)\n",
    "        \n",
    "        status_widget.value = f\"<b>Status:</b> Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\"\n",
    "        logger.info(f\"‚úì Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\")\n",
    "        \n",
    "        # Move to next page\n",
    "        on_skip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error saving annotations: {e}\"\n",
    "        logger.error(f\"Error saving annotations: {e}\")\n",
    "\n",
    "w_bbox.on_submit(on_submit)\n",
    "\n",
    "# Output widget for bbox changes\n",
    "w_out = widgets.Output()\n",
    "\n",
    "def on_bbox_change(change):\n",
    "    w_out.clear_output(wait=True)\n",
    "    with w_out:\n",
    "        current_boxes = change[\"new\"]\n",
    "        print(f\"Page {w_progress.value}: {len(current_boxes)} bounding boxes\")\n",
    "        if current_boxes:\n",
    "            print(json.dumps(current_boxes, indent=2))\n",
    "        pageAndBoundingBoxes[w_progress.value] = current_boxes\n",
    "\n",
    "w_bbox.observe(on_bbox_change, names=[\"bboxes\"])\n",
    "\n",
    "# Create comprehensive widget container\n",
    "w_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üìù Robust Interactive Annotation Tool</h3>\"),\n",
    "    status_widget,\n",
    "    widgets.HBox([\n",
    "        question_widget,\n",
    "        widgets.HTML(\"<i>Tip: Use 'NAME', 'ID', 'CLASS' for student info fields</i>\")\n",
    "    ]),\n",
    "    w_progress,\n",
    "    w_bbox,\n",
    "    widgets.HTML(\"<b>Current Annotations:</b>\"),\n",
    "    w_out,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='margin-top: 10px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;'>\n",
    "    <b>Instructions:</b><br>\n",
    "    ‚Ä¢ Draw bounding boxes around answer areas<br>\n",
    "    ‚Ä¢ Label each box with question number or field name<br>\n",
    "    ‚Ä¢ Use 'Submit' to save and move to next page<br>\n",
    "    ‚Ä¢ Use 'Skip' to move without saving<br>\n",
    "    ‚Ä¢ Ensure NAME, ID, and CLASS fields are marked\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "print(\"\\nüéØ Interactive annotation widget ready!\")\n",
    "print(\"Use the widget below to review and adjust bounding boxes.\")\n",
    "\n",
    "w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "üéâ STEP 3: ANNOTATION EXTRACTION COMPLETED\n",
      "======================================================================\n",
      "üìä Annotation Statistics:\n",
      "   Total pages annotated: 2\n",
      "   Total bounding boxes: 8\n",
      "   Average boxes per page: 4.0\n",
      "\n",
      "üè∑Ô∏è Label Distribution:\n",
      "   CLASS: 1 boxes\n",
      "   ID: 1 boxes\n",
      "   NAME: 1 boxes\n",
      "   Q1: 1 boxes\n",
      "   Q2: 1 boxes\n",
      "   Q3: 1 boxes\n",
      "   Q4: 1 boxes\n",
      "   Q5: 1 boxes\n",
      "\n",
      "‚úÖ Required Field Coverage:\n",
      "   ‚úì NAME: Found on 1/2 pages\n",
      "   ‚úì ID: Found on 1/2 pages\n",
      "   ‚úì CLASS: Found on 1/2 pages\n",
      "\n",
      "üìÅ Generated Files:\n",
      "   ‚úÖ AI annotations: ../marking_form/VTC Test/annotations/ai_annotations.json\n",
      "   ‚úÖ Final annotations: ../marking_form/VTC Test/annotations/annotations.json\n",
      "   ‚úÖ Page images: ../marking_form/VTC Test/images/ (8 files)\n",
      "\n",
      "üéØ Next Steps:\n",
      "   ‚úÖ All required fields present - ready for Step 4\n",
      "   1. Proceed to Step 4: Scoring Preprocessing\n",
      "   2. The annotations will be used for answer extraction\n",
      "\n",
      "üí° Quality Assurance:\n",
      "   ‚Ä¢ Robust OCR with retry logic and caching\n",
      "   ‚Ä¢ Comprehensive coordinate validation and scaling\n",
      "   ‚Ä¢ Interactive review and adjustment capability\n",
      "   ‚Ä¢ Detailed processing statistics and error handling\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Robust Step 3 completed successfully!\n",
      "Ready for answer extraction and grading!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final summary and validation\n",
    "def generate_annotation_summary():\n",
    "    \"\"\"Generate comprehensive annotation summary and validation report.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üéâ STEP 3: ANNOTATION EXTRACTION COMPLETED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load final annotations\n",
    "    final_annotations = {}\n",
    "    if os.path.exists(annotations_path):\n",
    "        with open(annotations_path, \"r\") as f:\n",
    "            final_annotations = json.load(f)\n",
    "    \n",
    "    # Generate statistics\n",
    "    total_pages = len(final_annotations)\n",
    "    total_boxes = sum(len(boxes) for boxes in final_annotations.values())\n",
    "    \n",
    "    # Analyze annotation types\n",
    "    label_counts = {}\n",
    "    required_fields = ['NAME', 'ID', 'CLASS']\n",
    "    pages_with_required = {field: 0 for field in required_fields}\n",
    "    \n",
    "    for page, boxes in final_annotations.items():\n",
    "        page_labels = set()\n",
    "        for box in boxes:\n",
    "            label = box.get('label', 'Unknown')\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "            page_labels.add(label)\n",
    "        \n",
    "        # Check for required fields\n",
    "        for field in required_fields:\n",
    "            if field in page_labels:\n",
    "                pages_with_required[field] += 1\n",
    "    \n",
    "    print(f\"üìä Annotation Statistics:\")\n",
    "    print(f\"   Total pages annotated: {total_pages}\")\n",
    "    print(f\"   Total bounding boxes: {total_boxes}\")\n",
    "    print(f\"   Average boxes per page: {total_boxes/total_pages:.1f}\" if total_pages > 0 else \"   No pages annotated\")\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Label Distribution:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"   {label}: {count} boxes\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Required Field Coverage:\")\n",
    "    all_required_present = True\n",
    "    for field in required_fields:\n",
    "        coverage = pages_with_required[field]\n",
    "        status = \"‚úì\" if coverage > 0 else \"‚ùå\"\n",
    "        print(f\"   {status} {field}: Found on {coverage}/{total_pages} pages\")\n",
    "        if coverage == 0:\n",
    "            all_required_present = False\n",
    "    \n",
    "    print(f\"\\nüìÅ Generated Files:\")\n",
    "    print(f\"   ‚úÖ AI annotations: {ai_annotations_path}\")\n",
    "    print(f\"   ‚úÖ Final annotations: {annotations_path}\")\n",
    "    print(f\"   ‚úÖ Page images: {base_path_images} ({len(files)} files)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    if all_required_present:\n",
    "        print(f\"   ‚úÖ All required fields present - ready for Step 4\")\n",
    "        print(f\"   1. Proceed to Step 4: Scoring Preprocessing\")\n",
    "        print(f\"   2. The annotations will be used for answer extraction\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Missing required fields - please review annotations\")\n",
    "        print(f\"   1. Use the annotation widget to add missing NAME/ID/CLASS fields\")\n",
    "        print(f\"   2. Ensure all pages have student identification fields\")\n",
    "        print(f\"   3. Then proceed to Step 4\")\n",
    "    \n",
    "    print(f\"\\nüí° Quality Assurance:\")\n",
    "    print(f\"   ‚Ä¢ Robust OCR with retry logic and caching\")\n",
    "    print(f\"   ‚Ä¢ Comprehensive coordinate validation and scaling\")\n",
    "    print(f\"   ‚Ä¢ Interactive review and adjustment capability\")\n",
    "    print(f\"   ‚Ä¢ Detailed processing statistics and error handling\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ Robust Step 3 completed successfully!\")\n",
    "    print(\"Ready for answer extraction and grading!\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "# Generate the summary\n",
    "generate_annotation_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
