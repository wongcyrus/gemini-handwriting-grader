{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Define Answer Bounding Boxes\n",
    "1. Convert the exam PDF into page images.\n",
    "2. Auto-detect bounding boxes with AI.\n",
    "3. Manually review and adjust each answer region.\n",
    "\n",
    "**Features:**\n",
    "- ‚úÖ Comprehensive validation of input files and setup\n",
    "- ‚úÖ Robust OCR processing with retry logic and caching\n",
    "- ‚úÖ Progress tracking for multi-page processing\n",
    "- ‚úÖ Coordinate validation and scaling\n",
    "- ‚úÖ Robust error handling and recovery\n",
    "- ‚úÖ Detailed processing reports and validation summaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following command extracts cache for the sample to speed up and reduce costs for the demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grading_utils import (\n",
    "    setup_paths, create_directories, init_gemini_client, \n",
    "    validate_required_files, print_validation_summary\n",
    ")\n",
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "from agents.annotation_agent.agent import extract_annotations_with_ai\n",
    "from typing import List\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "prefix = \"VTC Test\"\n",
    "paths = setup_paths(prefix, \"sample\")\n",
    "# Configuration - can be adjusted for testing\n",
    "number_of_pages = 2  # Set to specific number for testing, or use len(pages) after conversion\n",
    "\n",
    "# Validate required files exist\n",
    "missing_files = validate_required_files(paths)\n",
    "if missing_files:\n",
    "    print(\"‚ùå Setup validation failed!\")\n",
    "    for file in missing_files:\n",
    "        print(f\"  Missing: {file}\")\n",
    "    raise FileNotFoundError(\"Please ensure all required files are present.\")\n",
    "\n",
    "pdf_file = paths[\"pdf_file\"]\n",
    "\n",
    "\n",
    "\n",
    "print(\"‚úÖ Setup validation passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust directory creation and PDF conversion\n",
    "try:\n",
    "    # Extract paths from setup\n",
    "    file_name = paths[\"file_name\"]\n",
    "    base_path = paths[\"base_path\"]\n",
    "    base_path_images = paths[\"base_path_images\"]\n",
    "    base_path_annotations = paths[\"base_path_annotations\"]\n",
    "\n",
    "    # Create directories with error handling\n",
    "    create_directories(paths)\n",
    "    logger.info(\"‚úì Created all necessary directories\")\n",
    "\n",
    "    # Convert PDF to images with progress tracking\n",
    "    logger.info(\"Converting PDF to images...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    pages = convert_from_path(pdf_file, fmt='jpeg')\n",
    "    conversion_time = time.time() - start_time\n",
    "    \n",
    "    logger.info(f\"‚úì Converted PDF to {len(pages)} images in {conversion_time:.2f}s\")\n",
    "    \n",
    "    # Save images with progress tracking\n",
    "    for count, page in enumerate(tqdm(pages, desc=\"Saving images\")):\n",
    "        image_path = f'{base_path_images}{count}.jpg'\n",
    "        page.save(image_path, 'JPEG')\n",
    "    \n",
    "    logger.info(f\"‚úì Saved {len(pages)} images to {base_path_images}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to convert PDF or create directories: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust utility functions with error handling\n",
    "def update_json_file(annotations, path):\n",
    "    \"\"\"Update JSON file with error handling.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        with open(path, \"w\") as f:\n",
    "            json.dump(annotations, f, indent=4)\n",
    "        logger.info(f\"‚úì Updated annotations file: {path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to update JSON file {path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def image_to_data_url(filename):\n",
    "    \"\"\"Convert image to data URL with error handling.\"\"\"\n",
    "    try:\n",
    "        ext = filename.split(\".\")[-1].lower()\n",
    "        if ext == 'jpg':\n",
    "            ext = 'jpeg'\n",
    "        prefix = f\"data:image/{ext};base64,\"\n",
    "        \n",
    "        with open(filename, \"rb\") as f:\n",
    "            img = f.read()\n",
    "        return prefix + base64.b64encode(img).decode(\"utf-8\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to convert image to data URL {filename}: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úì Utility functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The extraction prompt is now encapsulated within the annotation_agent\n",
    "logger.info(\"üîç Using agent-managed prompt for extraction\")\n",
    "\n",
    "print(\"üîç Starting bounding box extraction...\")\n",
    "print(f\"Processing {number_of_pages} pages with OCR\")\n",
    "\n",
    "aiAnnotation = {}\n",
    "processing_stats = {\n",
    "    'total_pages': number_of_pages,\n",
    "    'successful_pages': 0,\n",
    "    'failed_pages': 0,\n",
    "    'total_boxes': 0,\n",
    "    'processing_time': 0\n",
    "}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Process each page with progress tracking\n",
    "for i in tqdm(range(number_of_pages), desc=\"Processing pages\"):\n",
    "    image_path = base_path_images + f\"{i}.jpg\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing page {i} ({image_path})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    try:\n",
    "        # Validate image exists\n",
    "        if not os.path.exists(image_path):\n",
    "            raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
    "        \n",
    "        # Use OCR with retry logic\n",
    "        result = await extract_annotations_with_ai(image_path)\n",
    "        \n",
    "        # Convert Pydantic model to dict and extract boxes\n",
    "        boxes_dict = [box.model_dump() for box in result.boxes]\n",
    "        aiAnnotation[str(i)] = boxes_dict\n",
    "        \n",
    "        processing_stats['successful_pages'] += 1\n",
    "        processing_stats['total_boxes'] += len(boxes_dict)\n",
    "        \n",
    "        print(f\"‚úì Page {i}: Found {len(boxes_dict)} bounding boxes\")\n",
    "        if boxes_dict:\n",
    "            print(json.dumps(boxes_dict, indent=2))\n",
    "        \n",
    "        # Validate bounding boxes\n",
    "        for box in boxes_dict:\n",
    "            if box['width'] <= 0 or box['height'] <= 0:\n",
    "                logger.warning(f\"Invalid box dimensions on page {i}: {box}\")\n",
    "        if i != 0:\n",
    "            filtered_boxes = [b for b in boxes_dict if b['label'] not in {'NAME', 'ID', 'CLASS'}]\n",
    "            removed = len(boxes_dict) - len(filtered_boxes)\n",
    "            if removed:\n",
    "                print(f\"Removed {removed} NAME/ID/CLASS boxes from page {i}\")\n",
    "            boxes_dict = filtered_boxes\n",
    "            aiAnnotation[str(i)] = boxes_dict\n",
    "            processing_stats['total_boxes'] -= removed\n",
    "        if not boxes_dict:\n",
    "            print(\"  (No bounding boxes detected)\")\n",
    "            logger.warning(f\"No bounding boxes found on page {i}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to process page {i}: {type(e).__name__}: {e}\")\n",
    "        aiAnnotation[str(i)] = []\n",
    "        processing_stats['failed_pages'] += 1\n",
    "\n",
    "processing_stats['processing_time'] = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"‚úÖ BOUNDING BOX EXTRACTION COMPLETED!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"üìä Processing Statistics:\")\n",
    "print(f\"   Total pages: {processing_stats['total_pages']}\")\n",
    "print(f\"   Successful: {processing_stats['successful_pages']}\")\n",
    "print(f\"   Failed: {processing_stats['failed_pages']}\")\n",
    "print(f\"   Total boxes found: {processing_stats['total_boxes']}\")\n",
    "print(f\"   Processing time: {processing_stats['processing_time']:.2f}s\")\n",
    "print(f\"   Average per page: {processing_stats['processing_time']/number_of_pages:.2f}s\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "backup = copy.deepcopy(aiAnnotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust coordinate scaling and validation\n",
    "import copy\n",
    "from PIL import Image\n",
    "\n",
    "# Get image dimensions for scaling\n",
    "sample_image_path = base_path_images + \"0.jpg\"\n",
    "try:\n",
    "    # Ensure backup exists (in case bounding box cell wasn't run or failed)\n",
    "    if 'backup' not in locals():\n",
    "        logger.warning(\"‚ö†Ô∏è Backup not found - loading AI annotations directly\")\n",
    "        ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "        if os.path.exists(ai_annotations_path):\n",
    "            with open(ai_annotations_path, \"r\") as f:\n",
    "                backup = json.load(f)\n",
    "            logger.info(\"‚úì Loaded backup from saved AI annotations\")\n",
    "        else:\n",
    "            logger.error(\"‚ùå No backup found and no saved annotations available\")\n",
    "            raise FileNotFoundError(\"AI annotations not found. Please run the bounding box extraction cell first.\")\n",
    "    \n",
    "    with Image.open(sample_image_path) as img:\n",
    "        width, height = img.size\n",
    "    \n",
    "    logger.info(f\"‚úì Image dimensions: {width}x{height}\")\n",
    "    print(f\"Image dimensions: Width: {width}, Height: {height}\")\n",
    "    \n",
    "    # Calculate scaling factors\n",
    "    x_scale = width / 1000.0\n",
    "    y_scale = height / 1000.0\n",
    "    \n",
    "    logger.info(f\"Scaling factors: x={x_scale:.3f}, y={y_scale:.3f}\")\n",
    "    \n",
    "    # Apply scaling with validation\n",
    "    aiAnnotation = copy.deepcopy(backup)\n",
    "    scaling_stats = {'scaled_boxes': 0, 'invalid_boxes': 0}\n",
    "    \n",
    "    for i in range(number_of_pages):\n",
    "        for item in aiAnnotation[str(i)]:\n",
    "            # Store original values for validation\n",
    "            orig_x, orig_y = item['x'], item['y']\n",
    "            orig_w, orig_h = item['width'], item['height']\n",
    "            \n",
    "            # Apply scaling\n",
    "            item['x'] = int(round(item['x'] * x_scale))\n",
    "            item['y'] = int(round(item['y'] * y_scale))\n",
    "            item['width'] = int(round(item['width'] * x_scale))\n",
    "            item['height'] = int(round(item['height'] * y_scale))\n",
    "            \n",
    "            # Validate scaled coordinates\n",
    "            if (item['x'] < 0 or item['y'] < 0 or \n",
    "                item['x'] + item['width'] > width or \n",
    "                item['y'] + item['height'] > height):\n",
    "                logger.warning(f\"Scaled box out of bounds on page {i}: {item}\")\n",
    "                scaling_stats['invalid_boxes'] += 1\n",
    "            else:\n",
    "                scaling_stats['scaled_boxes'] += 1\n",
    "    \n",
    "    print(f\"\\nüìê Coordinate Scaling Results:\")\n",
    "    print(f\"   Successfully scaled: {scaling_stats['scaled_boxes']} boxes\")\n",
    "    print(f\"   Invalid after scaling: {scaling_stats['invalid_boxes']} boxes\")\n",
    "    \n",
    "    # Save AI annotations\n",
    "    ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "    \n",
    "    with open(ai_annotations_path, \"w\") as f:\n",
    "        json.dump(aiAnnotation, f, indent=2)\n",
    "    \n",
    "    logger.info(f\"‚úì Saved AI annotations to: {ai_annotations_path}\")\n",
    "    print(f\"‚úì AI annotations saved to: {ai_annotations_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed to process image dimensions or scaling: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Annotation Review and Adjustment\n",
    "\n",
    "Please ensure the following are clearly marked on each page before grading:\n",
    "- **ID**: Student identification number\n",
    "- **NAME**: Student name field\n",
    "- **CLASS**: Student class/section\n",
    "\n",
    "Use the interactive widget below to review and adjust the AI-generated bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust interactive annotation widget with comprehensive features\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "import ipywidgets as widgets\n",
    "import glob\n",
    "\n",
    "# Initialize widget state\n",
    "page = 1\n",
    "pageAndBoundingBoxes = {}\n",
    "\n",
    "# Get all image files\n",
    "files = sorted(glob.glob(base_path_images + \"*.jpg\"))\n",
    "logger.info(f\"Found {len(files)} image files for annotation\")\n",
    "\n",
    "# Create progress widget\n",
    "w_progress = widgets.IntProgress(\n",
    "    value=0, \n",
    "    max=len(files), \n",
    "    description=\"Progress\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# File paths\n",
    "annotations_path = base_path_annotations + \"annotations.json\"\n",
    "ai_annotations_path = base_path_annotations + \"ai_annotations.json\"\n",
    "\n",
    "# Load existing annotations with priority: manual > AI\n",
    "annotations = {}\n",
    "\n",
    "# Load AI annotations first (as base)\n",
    "if os.path.exists(ai_annotations_path):\n",
    "    try:\n",
    "        with open(ai_annotations_path, \"r\") as f: \n",
    "            annotations = json.load(f)\n",
    "        logger.info(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "        print(f\"‚úì Loaded AI annotations for {len(annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load AI annotations: {e}\")\n",
    "\n",
    "# Then merge/override with manual annotations if they exist\n",
    "if os.path.exists(annotations_path):\n",
    "    try:\n",
    "        with open(annotations_path, \"r\") as f: \n",
    "            manual_annotations = json.load(f)\n",
    "            annotations.update(manual_annotations)  # Manual annotations take priority\n",
    "        logger.info(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "        print(f\"‚úì Merged manual annotations for {len(manual_annotations)} pages\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load manual annotations: {e}\")\n",
    "\n",
    "print(f\"Total pages with annotations: {list(annotations.keys())}\")\n",
    "\n",
    "# Create question input widget\n",
    "question_widget = widgets.Text(\n",
    "    value=\"\", \n",
    "    placeholder=\"Enter question label (e.g., '1', '2', 'NAME', 'ID')\", \n",
    "    description=\"Question:\",\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Create status widget\n",
    "status_widget = widgets.HTML(\n",
    "    value=\"<b>Status:</b> Ready to annotate\",\n",
    "    description=\"\"\n",
    ")\n",
    "\n",
    "# Create bbox widget\n",
    "w_bbox = BBoxWidget(\n",
    "    image=image_to_data_url(files[0]) if files else None\n",
    ")\n",
    "w_bbox.attach(question_widget, name=\"label\")\n",
    "\n",
    "# Load initial bounding boxes\n",
    "initial_page = str(w_progress.value)\n",
    "if initial_page in annotations:\n",
    "    w_bbox.bboxes = annotations[initial_page]\n",
    "    status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[initial_page])} boxes for page {w_progress.value}\"\n",
    "else:\n",
    "    w_bbox.bboxes = []\n",
    "    status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "\n",
    "# Robust skip function\n",
    "def on_skip():\n",
    "    if w_progress.value + 1 >= len(files):\n",
    "        status_widget.value = f\"<b>Status:</b> Already at the last page ({len(files)-1})\"\n",
    "        logger.info(f\"Already at the last page ({len(files)-1})\")\n",
    "        return\n",
    "    \n",
    "    w_progress.value += 1\n",
    "    current_page = str(w_progress.value)\n",
    "    \n",
    "    try:\n",
    "        # Load new image in the widget\n",
    "        image_file = files[w_progress.value]\n",
    "        w_bbox.image = image_to_data_url(image_file)\n",
    "        \n",
    "        # Load bounding boxes for current page\n",
    "        if current_page in annotations:\n",
    "            w_bbox.bboxes = annotations[current_page]\n",
    "            status_widget.value = f\"<b>Status:</b> Loaded {len(annotations[current_page])} boxes for page {w_progress.value}\"\n",
    "            logger.info(f\"‚úì Loaded {len(annotations[current_page])} bounding boxes for page {w_progress.value}\")\n",
    "        else:\n",
    "            w_bbox.bboxes = []\n",
    "            status_widget.value = f\"<b>Status:</b> No annotations found for page {w_progress.value}\"\n",
    "            logger.warning(f\"‚ö†Ô∏è No annotations found for page {w_progress.value}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error loading page {w_progress.value}: {e}\"\n",
    "        logger.error(f\"Error loading page {w_progress.value}: {e}\")\n",
    "\n",
    "w_bbox.on_skip(on_skip)\n",
    "\n",
    "# Robust submit function\n",
    "def on_submit():\n",
    "    try:\n",
    "        current_page = str(w_progress.value)\n",
    "        \n",
    "        # Save annotations for current image\n",
    "        annotations[current_page] = w_bbox.bboxes\n",
    "        update_json_file(annotations, annotations_path)\n",
    "        \n",
    "        status_widget.value = f\"<b>Status:</b> Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\"\n",
    "        logger.info(f\"‚úì Saved {len(w_bbox.bboxes)} annotations for page {w_progress.value}\")\n",
    "        \n",
    "        # Move to next page\n",
    "        on_skip()\n",
    "        \n",
    "    except Exception as e:\n",
    "        status_widget.value = f\"<b>Status:</b> Error saving annotations: {e}\"\n",
    "        logger.error(f\"Error saving annotations: {e}\")\n",
    "\n",
    "w_bbox.on_submit(on_submit)\n",
    "\n",
    "# Output widget for bbox changes\n",
    "w_out = widgets.Output()\n",
    "\n",
    "def on_bbox_change(change):\n",
    "    w_out.clear_output(wait=True)\n",
    "    with w_out:\n",
    "        current_boxes = change[\"new\"]\n",
    "        print(f\"Page {w_progress.value}: {len(current_boxes)} bounding boxes\")\n",
    "        if current_boxes:\n",
    "            print(json.dumps(current_boxes, indent=2))\n",
    "        pageAndBoundingBoxes[w_progress.value] = current_boxes\n",
    "\n",
    "w_bbox.observe(on_bbox_change, names=[\"bboxes\"])\n",
    "\n",
    "# Create comprehensive widget container\n",
    "w_container = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üìù Robust Interactive Annotation Tool</h3>\"),\n",
    "    status_widget,\n",
    "    widgets.HBox([\n",
    "        question_widget,\n",
    "        widgets.HTML(\"<i>Tip: Use 'NAME', 'ID', 'CLASS' for student info fields</i>\")\n",
    "    ]),\n",
    "    w_progress,\n",
    "    w_bbox,\n",
    "    widgets.HTML(\"<b>Current Annotations:</b>\"),\n",
    "    w_out,\n",
    "    widgets.HTML(\"\"\"\n",
    "    <div style='margin-top: 10px; padding: 10px; background-color: #f0f0f0; border-radius: 5px;'>\n",
    "    <b>Instructions:</b><br>\n",
    "    ‚Ä¢ Draw bounding boxes around answer areas<br>\n",
    "    ‚Ä¢ Label each box with question number or field name<br>\n",
    "    ‚Ä¢ Use 'Submit' to save and move to next page<br>\n",
    "    ‚Ä¢ Use 'Skip' to move without saving<br>\n",
    "    ‚Ä¢ Ensure NAME, ID, and CLASS fields are marked\n",
    "    </div>\n",
    "    \"\"\")\n",
    "])\n",
    "\n",
    "print(\"\\nüéØ Interactive annotation widget ready!\")\n",
    "print(\"Use the widget below to review and adjust bounding boxes.\")\n",
    "\n",
    "w_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and validation\n",
    "def generate_annotation_summary():\n",
    "    \"\"\"Generate comprehensive annotation summary and validation report.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"üéâ STEP 3: ANNOTATION EXTRACTION COMPLETED\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Load final annotations\n",
    "    final_annotations = {}\n",
    "    if os.path.exists(annotations_path):\n",
    "        with open(annotations_path, \"r\") as f:\n",
    "            final_annotations = json.load(f)\n",
    "    \n",
    "    # Generate statistics\n",
    "    total_pages = len(final_annotations)\n",
    "    total_boxes = sum(len(boxes) for boxes in final_annotations.values())\n",
    "    \n",
    "    # Analyze annotation types\n",
    "    label_counts = {}\n",
    "    required_fields = ['NAME', 'ID', 'CLASS']\n",
    "    pages_with_required = {field: 0 for field in required_fields}\n",
    "    \n",
    "    for page, boxes in final_annotations.items():\n",
    "        page_labels = set()\n",
    "        for box in boxes:\n",
    "            label = box.get('label', 'Unknown')\n",
    "            label_counts[label] = label_counts.get(label, 0) + 1\n",
    "            page_labels.add(label)\n",
    "        \n",
    "        # Check for required fields\n",
    "        for field in required_fields:\n",
    "            if field in page_labels:\n",
    "                pages_with_required[field] += 1\n",
    "    \n",
    "    print(f\"üìä Annotation Statistics:\")\n",
    "    print(f\"   Total pages annotated: {total_pages}\")\n",
    "    print(f\"   Total bounding boxes: {total_boxes}\")\n",
    "    print(f\"   Average boxes per page: {total_boxes/total_pages:.1f}\" if total_pages > 0 else \"   No pages annotated\")\n",
    "    \n",
    "    print(f\"\\nüè∑Ô∏è Label Distribution:\")\n",
    "    for label, count in sorted(label_counts.items()):\n",
    "        print(f\"   {label}: {count} boxes\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Required Field Coverage:\")\n",
    "    all_required_present = True\n",
    "    for field in required_fields:\n",
    "        coverage = pages_with_required[field]\n",
    "        status = \"‚úì\" if coverage > 0 else \"‚ùå\"\n",
    "        print(f\"   {status} {field}: Found on {coverage}/{total_pages} pages\")\n",
    "        if coverage == 0:\n",
    "            all_required_present = False\n",
    "    \n",
    "    print(f\"\\nüìÅ Generated Files:\")\n",
    "    print(f\"   ‚úÖ AI annotations: {ai_annotations_path}\")\n",
    "    print(f\"   ‚úÖ Final annotations: {annotations_path}\")\n",
    "    print(f\"   ‚úÖ Page images: {base_path_images} ({len(files)} files)\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    if all_required_present:\n",
    "        print(f\"   ‚úÖ All required fields present - ready for Step 4\")\n",
    "        print(f\"   1. Proceed to Step 4: Scoring Preprocessing\")\n",
    "        print(f\"   2. The annotations will be used for answer extraction\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è Missing required fields - please review annotations\")\n",
    "        print(f\"   1. Use the annotation widget to add missing NAME/ID/CLASS fields\")\n",
    "        print(f\"   2. Ensure all pages have student identification fields\")\n",
    "        print(f\"   3. Then proceed to Step 4\")\n",
    "    \n",
    "    print(f\"\\nüí° Quality Assurance:\")\n",
    "    print(f\"   ‚Ä¢ Robust OCR with retry logic and caching\")\n",
    "    print(f\"   ‚Ä¢ Comprehensive coordinate validation and scaling\")\n",
    "    print(f\"   ‚Ä¢ Interactive review and adjustment capability\")\n",
    "    print(f\"   ‚Ä¢ Detailed processing statistics and error handling\")\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"‚úÖ Robust Step 3 completed successfully!\")\n",
    "    print(\"Ready for answer extraction and grading!\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "# Generate the summary\n",
    "generate_annotation_summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
