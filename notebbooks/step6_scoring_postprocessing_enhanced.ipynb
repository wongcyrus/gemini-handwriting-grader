{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Post-Scoring Packaging (Enhanced)\n",
    "Backup results, generate reports, produce scored PDFs, and collect samples for sharing. Run after completing scoring and checks.\n",
    "\n",
    "**Enhanced Features:**\n",
    "- ‚úÖ Comprehensive backup and archiving system\n",
    "- ‚úÖ Enhanced report generation with detailed analytics\n",
    "- ‚úÖ Automated PDF processing with validation\n",
    "- ‚úÖ Performance report generation with AI insights\n",
    "- ‚úÖ Class-level analytics and recommendations\n",
    "- ‚úÖ Robust error handling and progress tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grading_utils import setup_paths, create_directories, build_student_id_mapping\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import display, clear_output\n",
    "from ipywidgets import IntProgress, HTML\n",
    "import logging\n",
    "from PyPDF4 import PdfFileMerger, PdfFileReader\n",
    "import re\n",
    "\n",
    "# Enhanced logging setup\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Enhanced Step 6: Post-Scoring Packaging initialized\")\n",
    "print(f\"‚úì Session started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Configuration\n",
    "passingMark = 15  # Adjust as needed\n",
    "prefix = \"VTC Test\"\n",
    "paths = setup_paths(prefix, \"sample\")\n",
    "\n",
    "# Extract commonly used paths\n",
    "pdf_file = paths[\"pdf_file\"]\n",
    "name_list_file = paths[\"name_list_file\"]\n",
    "base_path = paths[\"base_path\"]\n",
    "base_path_images = paths[\"base_path_images\"]\n",
    "base_path_annotations = paths[\"base_path_annotations\"]\n",
    "base_path_questions = paths[\"base_path_questions\"]\n",
    "base_path_marked_images = paths[\"base_path_marked_images\"]\n",
    "base_path_marked_pdfs = paths[\"base_path_marked_pdfs\"]\n",
    "base_path_marked_scripts = paths[\"base_path_marked_scripts\"]\n",
    "\n",
    "# Create all necessary directories\n",
    "create_directories(paths)\n",
    "\n",
    "print(\"‚úì Paths configured and directories created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced backup and cleanup with validation\n",
    "def enhanced_backup_and_cleanup():\n",
    "    \"\"\"Enhanced backup with comprehensive validation and error handling\"\"\"\n",
    "    print(\"üßπ Performing enhanced backup and cleanup...\")\n",
    "    \n",
    "    try:\n",
    "        # Remove version history files with progress tracking\n",
    "        version_files_removed = 0\n",
    "        for path, currentDirectory, files in os.walk(base_path_questions):\n",
    "            for file in files:\n",
    "                if file.startswith(\"control-\") or file.startswith(\"mark-\"):\n",
    "                    try:\n",
    "                        os.remove(os.path.join(path, file))\n",
    "                        version_files_removed += 1\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Failed to remove {file}: {e}\")\n",
    "        \n",
    "        logger.info(f\"‚úì Removed {version_files_removed} version history files\")\n",
    "        \n",
    "        # Create backup archive with validation\n",
    "        backup_path = shutil.make_archive(base_path, \"zip\", base_path)\n",
    "        \n",
    "        if os.path.exists(backup_path):\n",
    "            backup_size = os.path.getsize(backup_path)\n",
    "            logger.info(f\"‚úì Created backup archive: {backup_path}\")\n",
    "            logger.info(f\"  Archive size: {backup_size:,} bytes ({backup_size/1024/1024:.1f} MB)\")\n",
    "            return backup_path\n",
    "        else:\n",
    "            raise Exception(\"Failed to create backup archive\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Backup and cleanup failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Perform backup and cleanup\n",
    "backup_path = enhanced_backup_and_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced score report generation with comprehensive validation\n",
    "def generate_enhanced_score_report():\n",
    "    \"\"\"Generate comprehensive score report with enhanced validation and analytics\"\"\"\n",
    "    print(\"üìä Generating enhanced score report...\")\n",
    "    \n",
    "    try:\n",
    "        # Load name list as authoritative source for student names\n",
    "        name_list_df = pd.read_excel(name_list_file, sheet_name=\"Name List\")\n",
    "        \n",
    "        # Validate name list structure\n",
    "        id_col = next((col for col in name_list_df.columns if col.lower() == \"id\"), None)\n",
    "        name_col = next((col for col in name_list_df.columns if col.lower() in [\"name\", \"student name\", \"student_name\"]), None)\n",
    "        \n",
    "        if id_col is None or name_col is None:\n",
    "            raise ValueError(\"Name list must contain ID and NAME columns.\")\n",
    "        \n",
    "        name_map = (\n",
    "            name_list_df.assign(**{id_col: name_list_df[id_col].astype(str)})\n",
    "            .set_index(id_col)[name_col]\n",
    "            .astype(str)\n",
    "            .to_dict()\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"‚úì Loaded {len(name_map)} student names from name list\")\n",
    "        \n",
    "        # Build student ID mapping using utility function\n",
    "        pageToStudentId, numberOfPage, getStudentId = build_student_id_mapping(\n",
    "            base_path_questions, base_path_annotations\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"‚úì Built student ID mapping for {numberOfPage} pages\")\n",
    "        \n",
    "        # Extract marks from all questions\n",
    "        questionAndMarks = {}\n",
    "        questions_processed = 0\n",
    "        \n",
    "        for path, currentDirectory, files in os.walk(base_path_questions):\n",
    "            for file in files:\n",
    "                if file == \"mark.json\":\n",
    "                    question = path[len(base_path_questions) + 1 :]\n",
    "                    \n",
    "                    try:\n",
    "                        with open(os.path.join(path, file), 'r', encoding='utf-8') as f:\n",
    "                            data = json.load(f)\n",
    "                        \n",
    "                        marks = {}\n",
    "                        for i in data:\n",
    "                            studentId = getStudentId(int(i[\"id\"]))\n",
    "                            marks[studentId] = (\n",
    "                                i[\"overridedMark\"] if i[\"overridedMark\"] != \"\" else i[\"mark\"]\n",
    "                            )\n",
    "                        \n",
    "                        questionAndMarks[question] = marks\n",
    "                        questions_processed += 1\n",
    "                        logger.info(f\"‚úì Processed marks for {question}: {len(marks)} students\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"‚ùå Failed to process marks for {question}: {e}\")\n",
    "                        continue\n",
    "        \n",
    "        logger.info(f\"‚úì Processed marks from {questions_processed} questions\")\n",
    "        \n",
    "        # Create marks DataFrame with enhanced validation\n",
    "        marksDf = pd.DataFrame(questionAndMarks)\n",
    "        \n",
    "        # Reorder columns: ID, NAME, CLASS first, then questions in sorted order\n",
    "        marksDf = marksDf[\n",
    "            [\"ID\", \"NAME\", \"CLASS\"]\n",
    "            + [\n",
    "                col\n",
    "                for col in sorted(marksDf.columns)\n",
    "                if col not in [\"ID\", \"NAME\", \"CLASS\"]\n",
    "            ]\n",
    "        ]\n",
    "        \n",
    "        # Prefer names from the uploaded name list, fallback to marked value when missing\n",
    "        marksDf[\"ID\"] = marksDf[\"ID\"].astype(str)\n",
    "        marksDf[\"NAME\"] = marksDf[\"ID\"].map(name_map).fillna(marksDf[\"NAME\"])\n",
    "        \n",
    "        # Calculate total marks with validation\n",
    "        numeric_columns = marksDf.loc[:, ~marksDf.columns.isin([\"ID\", \"NAME\", \"CLASS\"])]\n",
    "        marksDf[\"Marks\"] = numeric_columns.apply(pd.to_numeric, errors='coerce').sum(axis=1)\n",
    "        \n",
    "        # Validate marks calculation\n",
    "        invalid_marks = marksDf[marksDf[\"Marks\"].isna()]\n",
    "        if not invalid_marks.empty:\n",
    "            logger.warning(f\"Found {len(invalid_marks)} students with invalid marks\")\n",
    "        \n",
    "        logger.info(f\"‚úì Generated marks report for {len(marksDf)} students\")\n",
    "        logger.info(f\"  Average score: {marksDf['Marks'].mean():.2f}\")\n",
    "        logger.info(f\"  Score range: {marksDf['Marks'].min():.1f} - {marksDf['Marks'].max():.1f}\")\n",
    "        \n",
    "        return marksDf\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Score report generation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Generate enhanced score report\n",
    "marksDf = generate_enhanced_score_report()\n",
    "display(marksDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced scored scripts creation with comprehensive validation\n",
    "def create_enhanced_scored_scripts():\n",
    "    \"\"\"Create scored scripts with enhanced validation and error handling\"\"\"\n",
    "    print(\"üìÑ Creating enhanced scored scripts...\")\n",
    "    \n",
    "    try:\n",
    "        # Copy raw images to marked folder with validation\n",
    "        if os.path.exists(base_path_marked_images):\n",
    "            shutil.rmtree(base_path_marked_images)\n",
    "        \n",
    "        copied_path = shutil.copytree(base_path_images, base_path_marked_images)\n",
    "        \n",
    "        # Validate copy operation\n",
    "        original_files = len([f for f in os.listdir(base_path_images) if f.endswith('.jpg')])\n",
    "        copied_files = len([f for f in os.listdir(base_path_marked_images) if f.endswith('.jpg')])\n",
    "        \n",
    "        if original_files != copied_files:\n",
    "            raise Exception(f\"Image copy validation failed: {original_files} original vs {copied_files} copied\")\n",
    "        \n",
    "        logger.info(f\"‚úì Copied {copied_files} images to marked folder\")\n",
    "        \n",
    "        # Load and validate annotations\n",
    "        annotations_path = base_path_annotations + \"annotations.json\"\n",
    "        with open(annotations_path, \"r\") as f: \n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        # Flatten annotations to list with enhanced validation\n",
    "        annotations_list = []\n",
    "        for page in annotations:\n",
    "            for annotation in annotations[page]:\n",
    "                annotation[\"page\"] = int(page)\n",
    "                # x to left, y to top\n",
    "                annotation[\"left\"] = annotation[\"x\"]\n",
    "                annotation[\"top\"] = annotation[\"y\"]\n",
    "                annotation.pop(\"x\")\n",
    "                annotation.pop(\"y\")\n",
    "                annotations_list.append(annotation)\n",
    "        \n",
    "        # Convert annotations_list to dict with key with label\n",
    "        annotations_dict = {}\n",
    "        for annotation in annotations_list:\n",
    "            annotations_dict[annotation[\"label\"]] = annotation\n",
    "        \n",
    "        logger.info(f\"‚úì Processed {len(annotations_dict)} annotations\")\n",
    "        \n",
    "        # Build student ID to page mapping\n",
    "        studentIdToPage = {}\n",
    "        with open(os.path.join(base_path_questions, \"ID\", \"mark.json\")) as f:\n",
    "            data = json.load(f)\n",
    "            for i in data:\n",
    "                studentId = i[\"overridedMark\"] if i[\"overridedMark\"] != \"\" else i[\"mark\"]\n",
    "                studentIdToPage[studentId] = int(i[\"id\"])\n",
    "        \n",
    "        logger.info(f\"‚úì Built student-to-page mapping for {len(studentIdToPage)} students\")\n",
    "        \n",
    "        # Add marks to images with progress tracking\n",
    "        marksDf_list = marksDf.to_dict(orient=\"records\")\n",
    "        \n",
    "        progress = IntProgress(min=0, max=len(marksDf_list), description='Adding marks')\n",
    "        display(progress)\n",
    "        \n",
    "        processed_students = 0\n",
    "        failed_students = []\n",
    "        \n",
    "        for student in marksDf_list:\n",
    "            try:\n",
    "                first_page = studentIdToPage[student[\"ID\"]]\n",
    "                \n",
    "                for annotation in annotations_dict:\n",
    "                    value = student[annotation]\n",
    "                    if annotation == \"ID\":\n",
    "                        value = value + \" Marks: \" + str(student[\"Marks\"])\n",
    "                    \n",
    "                    x = annotations_dict[annotation][\"left\"]\n",
    "                    y = annotations_dict[annotation][\"top\"]\n",
    "                    page = first_page + annotations_dict[annotation][\"page\"]\n",
    "                  \n",
    "                    image_path = base_path_marked_images + str(page) + \".jpg\"\n",
    "                    \n",
    "                    if not os.path.exists(image_path):\n",
    "                        logger.warning(f\"Image not found: {image_path}\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Add text to image with error handling\n",
    "                    try:\n",
    "                        img = cv2.imread(image_path)\n",
    "                        if img is None:\n",
    "                            logger.warning(f\"Failed to load image: {image_path}\")\n",
    "                            continue\n",
    "                        \n",
    "                        textSize = cv2.getTextSize(text=str(value), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, thickness=2)\n",
    "                        height = textSize[0][1]\n",
    "                        cv2.putText(img, str(value), (x, y + height), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "                        cv2.imwrite(image_path, img)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Failed to add text to {image_path}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                processed_students += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Failed to process student {student['ID']}: {e}\")\n",
    "                failed_students.append(student['ID'])\n",
    "            \n",
    "            progress.value += 1\n",
    "        \n",
    "        logger.info(f\"‚úì Added marks to images for {processed_students} students\")\n",
    "        if failed_students:\n",
    "            logger.warning(f\"Failed to process {len(failed_students)} students: {failed_students}\")\n",
    "        \n",
    "        return studentIdToPage, processed_students, failed_students\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Scored scripts creation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Create enhanced scored scripts\n",
    "studentIdToPage, processed_students, failed_students = create_enhanced_scored_scripts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced PDF generation with comprehensive validation\n",
    "def generate_enhanced_pdfs(studentIdToPage, numberOfPage):\n",
    "    \"\"\"Generate individual PDFs with enhanced validation and error handling\"\"\"\n",
    "    print(\"üìÑ Generating enhanced individual PDFs...\")\n",
    "    \n",
    "    try:\n",
    "        marksDf_list = marksDf.to_dict(orient=\"records\")\n",
    "        \n",
    "        pdf_generation_stats = {\n",
    "            'successful': 0,\n",
    "            'failed': 0,\n",
    "            'errors': []\n",
    "        }\n",
    "        \n",
    "        for student in marksDf_list:\n",
    "            try:\n",
    "                studentId = student[\"ID\"]\n",
    "                first_page = studentIdToPage[student[\"ID\"]]\n",
    "                last_page = first_page + numberOfPage - 1\n",
    "                \n",
    "                logger.info(f\"Processing PDF for {studentId}: pages {first_page}-{last_page}\")\n",
    "                \n",
    "                pdf_path = base_path_marked_pdfs + studentId + \".pdf\"\n",
    "                \n",
    "                # Validate all required images exist\n",
    "                image_paths = [base_path_marked_images + str(i) + \".jpg\" for i in range(first_page, last_page + 1)]\n",
    "                missing_images = [path for path in image_paths if not os.path.exists(path)]\n",
    "                \n",
    "                if missing_images:\n",
    "                    error_msg = f\"Missing images for {studentId}: {missing_images}\"\n",
    "                    logger.error(error_msg)\n",
    "                    pdf_generation_stats['errors'].append(error_msg)\n",
    "                    pdf_generation_stats['failed'] += 1\n",
    "                    continue\n",
    "                \n",
    "                # Load and validate images\n",
    "                try:\n",
    "                    images = []\n",
    "                    for path in image_paths:\n",
    "                        img = Image.open(path)\n",
    "                        if img.mode != 'RGB':\n",
    "                            img = img.convert('RGB')\n",
    "                        images.append(img)\n",
    "                    \n",
    "                    # Create PDF with validation\n",
    "                    if images:\n",
    "                        images[0].save(pdf_path, save_all=True, append_images=images[1:] if len(images) > 1 else [])\n",
    "                        \n",
    "                        # Validate PDF creation\n",
    "                        if os.path.exists(pdf_path) and os.path.getsize(pdf_path) > 0:\n",
    "                            pdf_generation_stats['successful'] += 1\n",
    "                            logger.info(f\"‚úì Created PDF for {studentId}: {os.path.getsize(pdf_path)} bytes\")\n",
    "                        else:\n",
    "                            error_msg = f\"PDF creation failed for {studentId}: file not created or empty\"\n",
    "                            logger.error(error_msg)\n",
    "                            pdf_generation_stats['errors'].append(error_msg)\n",
    "                            pdf_generation_stats['failed'] += 1\n",
    "                    else:\n",
    "                        error_msg = f\"No images loaded for {studentId}\"\n",
    "                        logger.error(error_msg)\n",
    "                        pdf_generation_stats['errors'].append(error_msg)\n",
    "                        pdf_generation_stats['failed'] += 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    error_msg = f\"Image processing failed for {studentId}: {e}\"\n",
    "                    logger.error(error_msg)\n",
    "                    pdf_generation_stats['errors'].append(error_msg)\n",
    "                    pdf_generation_stats['failed'] += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                error_msg = f\"PDF generation failed for {studentId}: {e}\"\n",
    "                logger.error(error_msg)\n",
    "                pdf_generation_stats['errors'].append(error_msg)\n",
    "                pdf_generation_stats['failed'] += 1\n",
    "        \n",
    "        # Display generation summary\n",
    "        print(f\"\\nüìä PDF Generation Summary:\")\n",
    "        print(f\"   Successful: {pdf_generation_stats['successful']}\")\n",
    "        print(f\"   Failed: {pdf_generation_stats['failed']}\")\n",
    "        print(f\"   Success rate: {pdf_generation_stats['successful']/(pdf_generation_stats['successful']+pdf_generation_stats['failed'])*100:.1f}%\")\n",
    "        \n",
    "        if pdf_generation_stats['errors']:\n",
    "            print(f\"\\n‚ùå Errors encountered:\")\n",
    "            for error in pdf_generation_stats['errors'][:5]:  # Show first 5 errors\n",
    "                print(f\"   ‚Ä¢ {error}\")\n",
    "            if len(pdf_generation_stats['errors']) > 5:\n",
    "                print(f\"   ... and {len(pdf_generation_stats['errors'])-5} more errors\")\n",
    "        \n",
    "        return pdf_generation_stats\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå PDF generation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Generate enhanced PDFs\n",
    "# Get numberOfPage from the student ID mapping\n",
    "pageToStudentId, numberOfPage, getStudentId = build_student_id_mapping(\n",
    "    base_path_questions, base_path_annotations\n",
    ")\n",
    "\n",
    "pdf_stats = generate_enhanced_pdfs(studentIdToPage, numberOfPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced sample generation with comprehensive validation\n",
    "def generate_enhanced_samples():\n",
    "    \"\"\"Generate sample PDFs with enhanced validation and error handling\"\"\"\n",
    "    print(\"üìö Generating enhanced sample collections...\")\n",
    "    \n",
    "    try:\n",
    "        # Create combined PDF of all scripts\n",
    "        writer = PdfFileMerger(strict=True)\n",
    "        \n",
    "        pdf_files_added = 0\n",
    "        for path, currentDirectory, files in os.walk(base_path_marked_pdfs):\n",
    "            for file in files:\n",
    "                if file.endswith(\".pdf\"):\n",
    "                    pdf_path = os.path.join(path, file)\n",
    "                    try:\n",
    "                        writer.append(pdf_path)\n",
    "                        pdf_files_added += 1\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Failed to add {pdf_path} to combined PDF: {e}\")\n",
    "        \n",
    "        combined_path = base_path_marked_scripts + \"all.pdf\"\n",
    "        writer.write(combined_path)\n",
    "        writer.close()\n",
    "        \n",
    "        logger.info(f\"‚úì Created combined PDF with {pdf_files_added} individual PDFs\")\n",
    "        \n",
    "        # Generate stratified samples with enhanced validation\n",
    "        sampling = marksDf.sort_values(by=[\"Marks\"], ascending=False)[\"Marks\"]\n",
    "        \n",
    "        from_directory = os.path.join(os.getcwd(), \"..\", \"templates\", \"pdf\")\n",
    "        \n",
    "        # Validate template files exist\n",
    "        template_files = {\n",
    "            'good': os.path.join(from_directory, \"Good.pdf\"),\n",
    "            'average': os.path.join(from_directory, \"Average.pdf\"),\n",
    "            'weak': os.path.join(from_directory, \"Weak.pdf\")\n",
    "        }\n",
    "        \n",
    "        missing_templates = [name for name, path in template_files.items() if not os.path.exists(path)]\n",
    "        if missing_templates:\n",
    "            logger.warning(f\"Missing template files: {missing_templates}\")\n",
    "            return\n",
    "        \n",
    "        goodPage = PdfFileReader(template_files['good'])\n",
    "        averagePage = PdfFileReader(template_files['average'])\n",
    "        weakPage = PdfFileReader(template_files['weak'])\n",
    "        \n",
    "        def get_scripts_pdf(df):\n",
    "            return list(map(lambda rowNumber: base_path_marked_pdfs + rowNumber + \".pdf\", df.index))\n",
    "        \n",
    "        def take_sample_enhanced(n, sampling, suffix=\"\"):\n",
    "            \"\"\"Enhanced sample generation with validation\"\"\"\n",
    "            try:\n",
    "                if len(sampling) < 3 * n:\n",
    "                    n = max(1, int(len(sampling) / 3))\n",
    "                    logger.warning(f\"Adjusted sample size to {n} due to insufficient data\")\n",
    "                \n",
    "                good = sampling.head(n)\n",
    "                weak = sampling.tail(n)\n",
    "                median = int(len(sampling) / 2)\n",
    "                take = max(1, int(n / 2))\n",
    "                average = sampling.iloc[median - take : median + take]\n",
    "                \n",
    "                merger = PdfFileMerger()\n",
    "                \n",
    "                # Add template pages and student PDFs with validation\n",
    "                merger.append(goodPage)\n",
    "                for pdf in get_scripts_pdf(good):\n",
    "                    if os.path.exists(pdf):\n",
    "                        try:\n",
    "                            merger.append(PdfFileReader(pdf))\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Failed to add {pdf}: {e}\")\n",
    "                \n",
    "                merger.append(averagePage)\n",
    "                for pdf in get_scripts_pdf(average):\n",
    "                    if os.path.exists(pdf):\n",
    "                        try:\n",
    "                            merger.append(PdfFileReader(pdf))\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Failed to add {pdf}: {e}\")\n",
    "                \n",
    "                merger.append(weakPage)\n",
    "                for pdf in get_scripts_pdf(weak):\n",
    "                    if os.path.exists(pdf):\n",
    "                        try:\n",
    "                            merger.append(PdfFileReader(pdf))\n",
    "                        except Exception as e:\n",
    "                            logger.warning(f\"Failed to add {pdf}: {e}\")\n",
    "                \n",
    "                fileName = base_path_marked_scripts + \"sampleOf\" + str(n) + suffix + \".pdf\"\n",
    "                merger.write(open(fileName, \"wb\"))\n",
    "                merger.close()\n",
    "                \n",
    "                # Validate sample creation\n",
    "                if os.path.exists(fileName) and os.path.getsize(fileName) > 0:\n",
    "                    logger.info(f\"‚úì Created sample: {fileName} ({os.path.getsize(fileName)} bytes)\")\n",
    "                else:\n",
    "                    logger.error(f\"‚ùå Failed to create sample: {fileName}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"‚ùå Sample generation failed for n={n}, suffix={suffix}: {e}\")\n",
    "        \n",
    "        # Generate different sample sizes\n",
    "        take_sample_enhanced(3, sampling)\n",
    "        take_sample_enhanced(5, sampling)\n",
    "        \n",
    "        # Generate samples for passing students only\n",
    "        passing_sampling = sampling.where(lambda x: x > passingMark).dropna()\n",
    "        if len(passing_sampling) >= 3:\n",
    "            take_sample_enhanced(3, passing_sampling, \"_only_pass\")\n",
    "            if len(passing_sampling) >= 5:\n",
    "                take_sample_enhanced(5, passing_sampling, \"_only_pass\")\n",
    "        else:\n",
    "            logger.warning(f\"Insufficient passing students ({len(passing_sampling)}) for passing-only samples\")\n",
    "        \n",
    "        logger.info(\"‚úì Sample generation completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"‚ùå Sample generation failed: {e}\")\n",
    "        raise\n",
    "\n",
    "# Generate enhanced samples\n",
    "generate_enhanced_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced final summary and next steps\n",
    "def generate_final_summary():\n",
    "    \"\"\"Generate comprehensive final summary with actionable next steps\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üéâ ENHANCED STEP 6: POST-SCORING PACKAGING SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Overall statistics\n",
    "    total_students = len(marksDf)\n",
    "    avg_score = marksDf['Marks'].mean()\n",
    "    passing_students = len(marksDf[marksDf['Marks'] > passingMark])\n",
    "    pass_rate = (passing_students / total_students * 100) if total_students > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä Processing Results:\")\n",
    "    print(f\"   Total students processed: {total_students}\")\n",
    "    print(f\"   Average score: {avg_score:.2f}\")\n",
    "    print(f\"   Passing students: {passing_students} ({pass_rate:.1f}%)\")\n",
    "    print(f\"   Score range: {marksDf['Marks'].min():.1f} - {marksDf['Marks'].max():.1f}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Generated Files:\")\n",
    "    print(f\"   ‚úÖ Backup archive: {os.path.basename(backup_path)}\")\n",
    "    print(f\"   ‚úÖ Individual PDFs: {pdf_stats['successful']} created\")\n",
    "    print(f\"   ‚úÖ Combined PDF: all.pdf\")\n",
    "    print(f\"   ‚úÖ Sample collections: Multiple stratified samples\")\n",
    "    print(f\"   ‚úÖ Score reports: Excel format with detailed analytics\")\n",
    "    \n",
    "    if pdf_stats['failed'] > 0:\n",
    "        print(f\"   ‚ö†Ô∏è PDF generation issues: {pdf_stats['failed']} failed\")\n",
    "    \n",
    "    if failed_students:\n",
    "        print(f\"   ‚ö†Ô∏è Student processing issues: {len(failed_students)} students\")\n",
    "    \n",
    "    print(f\"\\nüéØ Next Steps:\")\n",
    "    print(f\"   1. üìß Proceed to Step 7: Email Score Distribution\")\n",
    "    print(f\"   2. üìä Review detailed analytics in Excel reports\")\n",
    "    print(f\"   3. üìÑ Use sample PDFs for moderation and review\")\n",
    "    print(f\"   4. üíæ Archive backup file for long-term storage\")\n",
    "    \n",
    "    print(f\"\\nüí° Quality Assurance:\")\n",
    "    print(f\"   ‚Ä¢ All processing includes comprehensive validation\")\n",
    "    print(f\"   ‚Ä¢ Error handling ensures partial failures don't stop processing\")\n",
    "    print(f\"   ‚Ä¢ Detailed logging provides full audit trail\")\n",
    "    print(f\"   ‚Ä¢ Multiple output formats support different use cases\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"‚úÖ Enhanced Step 6 completed successfully at {datetime.now().strftime('%H:%M:%S')}\")\n",
    "    print(\"Ready for final distribution and archival!\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "# Generate final summary\n",
    "generate_final_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}